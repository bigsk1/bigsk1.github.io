[
  
  {
    "title": "Ai Podcast Generator",
    "url": "/posts/AI-Podcast/",
    "categories": "ai",
    "tags": "docker, ai, node, anthropic, elevenlabs",
    "date": "2024-11-24 09:00:00 -0800",
    





    
    "snippet": "AI Podcast Generator üéôÔ∏èAn AI-powered tool that transforms YouTube videos into engaging podcast discussions. Features a modern web interface for easy use and optional CLI functionality. Downloads vi...",
    "content": "AI Podcast Generator üéôÔ∏èAn AI-powered tool that transforms YouTube videos into engaging podcast discussions. Features a modern web interface for easy use and optional CLI functionality. Downloads videos, transcribes them, and generates natural conversations between AI voices discussing the content.https://github.com/user-attachments/assets/daeb1068-6f63-499c-9790-8ac34a46a140Features  üéØ Modern web interface for easy podcast generation  üé• Embedded YouTube video player  üîä Interactive audio player for generated podcasts  üíæ History tracking of processed videos  ü§ñ Natural conversation generation using Claude AI or XAI  üó£Ô∏è Multiple AI voices using ElevenLabs  ‚ö° Real-time processing status updates  üìù Optional fact-checking of contentQuick Start with Docker Run üê≥  Install Docker.  Place your .env file in the same directory as this command. See the .env.example for detailsRun the following command:docker run -d --name podcast-app \\  --env-file .env \\  -p 5000:5000 \\  -p 5173:5173 \\  -v $(pwd)/public/audio:/app/public/audio \\  -v $(pwd)/output:/app/output \\  --restart unless-stopped \\  --health-cmd=\"curl -f http://localhost:5000/health || exit 1\" \\  --health-interval=30s \\  --health-timeout=10s \\  --health-retries=3 \\  bigsk1/podcast-ai:latestPrerequisites  Node.js 18 +  Python 3.10 +  FFmpeg installed and in PATH  ElevenLabs API key  Anthropic (Claude) or XAI API keyDocker Compose Setup üê≥You can run the application using Docker with these simple steps:  Clone the repository and navigate to it:git clone https://github.com/bigsk1/podcast-ai.gitcd podcast-ai      Create your .env file with required API keys and settings, see the .env.example        Using Docker Compose:  cd dockerdocker-compose up -d --buildThe application will be available at:  Frontend UI: http://localhost:5173To stop the container:docker-compose downNote: Generated audio files will be available in the public/audio directory, just like in the standard setup.Docker with Cuda for faster transcription on Nvidia GPUNote: This is only slightly faster as the transcription can go pretty quick anyway on cpu. To use make sure you have nvidia container toolkit and cudnn installed on host machine.  Test to see if you can run by first usingsudo docker run --rm --runtime=nvidia --gpus all ubuntu nvidia-smi  Run docker compose with cuda enabled transcription    docker compose -f cuda.docker-compose.yml up -d --build      Installation - Windows / Ubuntu  Clone the repository:    git clone https://github.com/bigsk1/podcast-ai.gitcd podcast-ai        Install frontend dependencies:    npm install        Set up Python environment and install dependencies:python -m venv venvsource venv/bin/activate  # Linux/Mac# orvenv\\Scripts\\activate     # WindowsInstall requirementspip install -r requirements.txt  Create .env file with your API keys:# ELEVENLABS VOICE ID'S - add your own voice id's VOICE1=111111111111VOICE2=111111111111# AI Model Settings - xai, anthropicAI_PROVIDER=anthropic# model name: grok-beta, claude-3-5-sonnet-latestMODEL_NAME=claude-3-5-sonnet-latest# Podcast Generation Settings# Minimum number of back-and-forth exchangesMIN_EXCHANGES=4# Maximum number of exchangesMAX_EXCHANGES=20# Minimum words per exchangeEXCHANGE_LENGTH_MIN_WORDS=20# Maximum words per exchangeEXCHANGE_LENGTH_MAX_WORDS=150# Audio Length Control# Target length for final podcast (in minutes)TARGET_LENGTH_MINUTES=3# Allowed deviation from target (20% = ¬±36 seconds for 3 min target)LENGTH_FLEXIBILITY=0.2# Target output length as ratio of source (0.2 = 20% of original)SOURCE_LENGTH_RATIO=0.2# Minimum podcast length in minutesMIN_PODCAST_LENGTH=2# Minimum podcast length in minutesMAX_PODCAST_LENGTH=5# Maximum podcast length in minutes# Content Coverage# comprehensive, summary, or highlights, humor, emotional, debateCOVERAGE_STYLE=highlights# Enable AI fact checkingFACT_CHECK_ENABLED=false# balanced, critical, or supportiveFACT_CHECK_STYLE=balanced          # Model SettingsTEMPERATURE=0.7MAX_TOKENS=8192LOGGING_LEVEL=DEBUG# Output DirectoryOUTPUT_DIR=output# ANTHROPIC API KEYANTHROPIC_API_KEY=your_key_here# ELEVENLABS API KEYELEVENLABS_API_KEY=your_key_here# For XAIXAI_BASE_URL=https://api.x.aiXAI_API_KEY=your_xai_key# Frontend configuration# if access on other machine on network change to actual server ipVITE_API_URL=http://localhost:5000         Change voice.json.example to voice.json and add your voice names and id‚Äôs from elevenlabs, this is a collection that you want to use, set the current voice id in the .env when running the app.        Make sure you have ffmpeg installed  Windowswinget install ffmpegLinuxsudo apt install ffmpegUsageWeb Interface  Start the backend server in one terminal:    python api.py        Start the frontend development server in another terminal:    npm run dev            Open http://localhost:5173 in your browser    Paste a YouTube URL and click ‚ÄúGenerate AI Podcast Review‚ÄùCLI Version (Optional)The tool can also be used from the command line:# Basic usagepython main.py \"https://www.youtube.com/watch?v=video_id\"# Skip audio generationpython main.py --no-audio \"https://www.youtube.com/watch?v=video_id\"# Generate without mergingpython main.py --no-merge \"https://www.youtube.com/watch?v=video_id\"# Merge audio files manuallypython merge_audio_cli.py output conversation.mp3OutputGenerated files are saved in:  UI version: public/audio/ directory  CLI version: output/ directoryConfiguration OptionsAll configuration options are set through the .env file. See the sample .env file above for common settings. Also make sure you have your elevenlabs voice id‚Äôs. The provided example voice id‚Äôs in voices.json won‚Äôt work for you, each account has it‚Äôs own specific id‚Äôs to match there api key.ExamplesCheck out the video on X.https://aicodelabs.io/emotional.mp3        Your browser does not support the audio element.https://aicodelabs.io/silo.mp3        Your browser does not support the audio element.https://aicodelabs.io/merged.mp3        Your browser does not support the audio element.In Progress  Adding Openai  Adding ollama  Add web search into fact checking of podcast  Add youtube API and add a search feature in header and seperate page for one click podcast generationTroubleshootingCould not locate cudnn_ops64_9.dllCould not locate cudnn_ops64_9.dll. Please make sure it is in your library path!Invalid handle. Cannot load symbol cudnnCreateTensorDescriptorTo resolve this:Install cuDNN: Download cuDNN from the NVIDIA cuDNN page https://developer.nvidia.com/cudnnHere‚Äôs how to add it to the PATH:Open System Environment Variables:Press Win + R, type sysdm.cpl, and hit Enter. Go to the Advanced tab, and click on Environment Variables. Edit the System PATH Variable:In the System variables section, find the Path variable, select it, and click Edit. Click New and add the path to the bin directory where cudnn_ops64_9.dll is located. Based on your setup, you would add:C:\\Program Files\\NVIDIA\\CUDNN\\v9.5\\bin\\12.6Apply and Restart:Click OK to close all dialog boxes, then restart your terminal (or any running applications) to apply the changes. Verify the Change:Open a new terminal and runwhere cudnn_ops64_9.dllpyaudio codec issueMake sure you have ffmpeg installed and added to PATH on windows terminal ( winget install ffmpeg )GithubPodcast-AI Github"
  },
  
  {
    "title": "Ollama Tools",
    "url": "/posts/Ollama-Tools/",
    "categories": "ai",
    "tags": "python, llm, ai, ollama",
    "date": "2024-08-04 03:00:00 -0700",
    





    
    "snippet": "Ollama Tools AiOllama tools is a side project I am working on to allow ollama models to use tools. What is a tool? A function that allows the AI to do something it navitily can‚Äôt like create a fold...",
    "content": "Ollama Tools AiOllama tools is a side project I am working on to allow ollama models to use tools. What is a tool? A function that allows the AI to do something it navitily can‚Äôt like create a folder and file on your locally machine. You can ask the AI to preform a certain task and based on the function you have created enable the AI to preform a task using tools. Some of the newer models like llama3.1 and llama3-groq-tool-use work well preforming these tasks.The goal is to create a large tools class that the Ai is aware of and can use one or more as needed based on a chat session. I have also added a vector databse with similarity score so the AI can referance previous tasks and conversations. Some of the next steps are to add new tools, add a way to drop any document into the folder and prompt the AI a certain way and it can use a tools to create RAG knowledge set and understand your data better.OverviewOllama Tools AI is a work-in-progress project focused on implementing advanced AI functionalities, including function calling and tool usage. This project aims to provide a robust and flexible framework for AI-driven tasks and interactions.Features  Function Calling: Seamlessly integrate and call various functions to perform tasks.  Tool Usage: Utilize different tools for enhanced AI capabilities.  Web Search: Use searXNG or Tavily for web searches  Create: The AI will create folders and files, read files, list files, delete files, web search and more..  DB Similarity: Every chat and tool use is saved in DB for future context aware AI responses.# API KeysTAVILY_API_KEY=tvly-# ModelsOLLAMA_MODEL=llama3-groq-tool-useEMBED_MODEL=nomic-embed-text# Search ConfigurationSEARCH_PROVIDER=SEARXNGSEARCH_RESULTS_LIMIT=5# URLsOLLAMA_URL=http://127.0.0.1:11434SEARXNG_URL=http://192.168.70.48:4000# Database ConfigurationDB_DIR=./chromadb  # database location realitive to current directoryN_CONTEXTS=3   # Number of contexts to retrieve from DB - you can adjust this for testingSIMILARITY_THRESHOLD=0.7  # Adjust this value to control context relevance (lower is more strict)# Debug print statements in terminal False or TrueDEBUG_MODE=FalseInstall dependenciespip install -r requirements.txtUsagepython ol.pyscreenshotsSearch resultsGithub Repoollama-tools-github"
  },
  
  {
    "title": "AI Screen Analyzer",
    "url": "/posts/AI-Screen-Analyzer/",
    "categories": "docker",
    "tags": "python, llm, claude, docker, ai, openai, ollama",
    "date": "2024-07-25 03:00:00 -0700",
    





    
    "snippet": "AI Screen AnalyzerAI Screen Analyzer is a powerful web application that allows users to capture screenshots, analyze them using various AI providers and models, and engage in conversations about th...",
    "content": "AI Screen AnalyzerAI Screen Analyzer is a powerful web application that allows users to capture screenshots, analyze them using various AI providers and models, and engage in conversations about the captured images.You can capture a website you like and then ask the AI to provide the code to build the same thing.You can capture any window or full screen ask OpenAI gpt-4o to describe anything about it and then switch providers and follow up with Claude or any Ollama model which will have the previous context and still understand the past conversation and image.Features  Screen Capture: Easily capture screenshots of your desktop or specific windows.  Multi-Model AI Analysis: Analyze images using multiple AI models:          OpenAI‚Äôs GPT-4 Vision      Anthropic‚Äôs Claude 3 Sonnet      Ollama‚Äôs local models (including LLaVA)        Intelligent Chat: Engage in conversations about the analyzed images or any other topic.  Model Switching: Seamlessly switch between different AI models for varied perspectives without losing context.  Dark/Light Mode: Toggle between dark and light themes for comfortable viewing.  Local Setup: Run the application locally for enhanced privacy and customization.  Docker: Run in docker because we all love docker.Quick StartDocker:  Add your api keys in .env   docker-compose up -d --buildvisit http://localhost:3000PrerequisitesBefore you begin, ensure you have met the following requirements:  Node.js (v18.0.0 or later) or just run in docker only  OpenAI API key - if you plan on using openai  Anthropic API key - if you plan on using Claude models  Ollama  (OPTIONAL for local model support)  Docker  (OPTIONAL but recommended)Installation  Clone the repository:    git clone https://github.com/bigsk1/ai-screen-analyzer.gitcd ai-screen-analyzer        Install dependencies for both the client and server:    npm install            Create a .env file in the root directory and add your API keys:    # for openai gpt-4o is used for image analysis and chat# ollama uses llava for image analysis    REACT_APP_OPENAI_API_KEY=your_openai_api_keyANTHROPIC_API_KEY=your_anthropic_api_keyANTHROPIC_MODEL=claude-3-sonnet-20240620OLLAMA_API_URL=http://localhost:11434  Usage  Start the server and react app:    npm run dev            Open your browser and navigate to http://localhost:3000.        Use the ‚ÄúStart Capturing‚Äù button to begin a screen capture.        Select the window or area you want to capture.        Click ‚ÄúCapture Screenshot‚Äù to analyze the image.        Choose an AI model from the dropdown menu to analyze the image or engage in chat.    Type your questions or comments in the chat box and press send.DockerThere is a docker-compose.yml file in root which will build the Dockerfile   docker-compose up -d --buildvisit http://localhost:3000To removedocker-compose downConfiguration  Add your OpenAI API Key in .env  To change the default Anthropic model, update the ANTHROPIC_MODEL variable in your .env files.  If using ollama and your host if different then change in the .env, by default when running nativly using npm run dev it uses locahost:11434 and when running docker it uses host.docker.internal:11434 so no need to change in the .envContributingContributions to the AI Screen Analyzer are welcome. Please follow these steps:  Fork the repository.  Create a new branch: git checkout -b feature/your-feature-name.  Make your changes and commit them: git commit -m 'Add some feature'.  Push to the branch: git push origin feature/your-feature-name.  Submit a pull request.Github Repohttps://github.com/bigsk1/ai-screen-analyzer"
  },
  
  {
    "title": "Claude Plus",
    "url": "/posts/Claude-Plus/",
    "categories": "docker",
    "tags": "python, llm, claude, docker, ai",
    "date": "2024-07-16 03:00:00 -0700",
    





    
    "snippet": "Claude Plus : AI-Powered Development AssistantI built an AI development assistant, currently a work in progress but give it a try.Claude Plus is an advanced AI-powered development assistant that co...",
    "content": "Claude Plus : AI-Powered Development AssistantI built an AI development assistant, currently a work in progress but give it a try.Claude Plus is an advanced AI-powered development assistant that combines the capabilities of Anthropic‚Äôs Claude AI with a suite of development tools. It‚Äôs designed to help developers with various tasks, from coding to project management, all through an interactive chat interface.Features  üß† Interact with Claude-3.5-Sonnet: Engage with the advanced AI, ask to build your ideas and code files and folders are made!.  üìÅ File System Manipulation: Claude will create, read, write and delete files and folders seamlessly on your system. The files tab shows date modified and size of files and folders in a list or grid view.  üîç Powerful Search: Utilize Tavily API or SearXNG to perform comprehensive searches. Claude also has search tool built in.  üí° Code Snippet Management: Highlight and manage code snippets efficiently. Have questions about an existing project drop the folder in the projects directory and Claude will have full access.  üìÇ Project Structure Management: Build and maintain complex project structures with ease.  üîß Code Analysis and Suggestions: Receive detailed analysis and improvement suggestions for your code.  üñºÔ∏è Image Analysis: Analyze images and gain insights with AI-powered image support.  ‚öôÔ∏è Automode: Automate tasks for increased efficiency and productivity. Set max iterations in env and Claude will cycle through that number of times automaticlly.  üîÑ Iterative Tracking: Monitor changes and iterations accurately during automode sessions.  ‚úÇÔ∏è Diff-Based Editing: Edit files using diff-based techniques for precise modifications.  üíª NEW console feature - You are able to run commands in the UI just like a terminal. Run python scripts within the UI!  ‚¨áÔ∏è NEW download projects folder You can download the entire projects directory with all your created folders and files directly from the UI now.This application leverages the power of Claude to enhance your development workflow, providing robust tools for file management, search, code analysis, and automation.Getting StartedPrerequisites  Python 3.10+  Node.js 18+  Anthropic API key  Tavily API key or SearXNG serverInstallation      Clone the repository:    git clone https://github.com/bigsk1/claude-plus.gitcd claude-plus            Set up the backend:    python -m venv venvsource venv/bin/activate  # On Windows use `venv\\Scripts\\activate`pip install -r requirements.txt            Set up the frontend:    cd frontendnpm install            Create a .env file in the root directory and add your API keys:    ANTHROPIC_API_KEY=your_anthropic_api_keyCLAUDE_MODEL=claude-3-5-sonnet-20240620SEARCH_PROVIDER=SEARXNG   # or TAVILYTAVILY_API_KEY=your_tavily_api_key  # If using Tavily SEARXNG_URL=your_searxng_url  # If using SearXNGMAX_ITERATIONS=5  # Number of automode iterations  Running the Application      Start the backend server:    uvicorn backend:app --host 0.0.0.0 --port 8000            In a new terminal, start the frontend development server from the frontend folder:    cd frontendnpm run dev            Open your browser and navigate to http://localhost:5173/  UsageClaude Plus offers a powerful suite of features to enhance your development workflow. Here‚Äôs how to make the most of this AI-powered assistant:1. Interactive Chat Interface  Engage with Claude: Use the chat interface to communicate with Claude, your AI development assistant.  Natural Language Queries: Ask questions, request code explanations, or seek advice on best practices.  Code Generation: Describe the functionality you need, and Claude will generate code snippets or entire files.  Debugging Assistance: Paste error messages or problematic code for Claude to analyze and suggest fixes.2. File and Image Management  File Upload: Easily upload files for Claude to analyze or work with. All uploaded files are stored in the projects/uploads folder.  Image Analysis: Upload images for Claude to describe and analyze, useful for UI/UX discussions or diagram interpretations.  Code Review: Upload your code files for Claude to review, suggest improvements, or explain complex sections. It will not only read your files you add but can modify and even delete if requested.3. Project Structure Management  File Explorer: Use the intuitive file explorer interface to manage your project structure directly in the UI.  Create: Add new files or folders to organize your project.  Edit: Modify existing files with syntax highlighting for various programming languages.  Delete: Remove unnecessary files or folders to keep your project clean.  Real-time Updates: All changes in the file explorer are immediately reflected in the projects folder.4. Automode for Autonomous Development  Activate Automode: Enable Claude to work autonomously on complex tasks or entire project setups.  Project Generation: Describe a project idea, and watch as Claude creates folder structures, files, and boilerplate code.  Iterative Development: Claude can refine and expand code over multiple iterations without constant user input.  Progress Tracking: Monitor Claude‚Äôs progress as it works through tasks in automode.  Sandbox Environment: All automode operations are confined to the projects folder, ensuring safe experimentation.5. Web Search Integration  Integrated Search: Perform web searches without leaving the chat interface.  Multiple Providers: Choose between SEARXNG (for privacy-focused searches) or Tavily (for AI-enhanced results).  Rich Markdown Display: Search results are presented in a readable, formatted markdown style.  Context-Aware Queries: Claude can perform searches based on your conversation context for more relevant results.6. Code Execution and Testing (In Progress)  Secure Sandbox: Run Python scripts directly within the chat interface.  Output Display: View the results of your code execution inline with your conversation.  Interactive Debugging: Step through code with Claude‚Äôs guidance to identify and fix issues.7. Version Control Integration (Coming Soon)  Git Commands: Perform basic git operations like commit, push, and pull directly from the chat.      Commit Message Assistance: Let Claude suggest meaningful commit messages based on your changes.    Chat History: Review past conversations and decisions with a searchable chat history.Remember, Claude Plus is continuously learning and improving. Don‚Äôt hesitate to experiment with different approaches and let us know about your experience!DockerThis project includes a Docker configurationDocker quick startSet your .env correctly in rootcd into docker folderdocker-compose up -dFrontend: http://localhost:5173You can always get the latest image by:docker pull ghcr.io/bigsk1/claude-plus:latestLocal Docker Setup  Ensure Docker and Docker Compose are installed on your system.  Navigate to the project root directory.      Build and run the development containers:    docker-compose -f docker/docker-compose.dev.yml up -d --build            Access the application:          Frontend: http://localhost:5173      The development setup includes hot-reloading for both frontend and backend, and maps the projects folder to persist data.VS Code Dev Container SetupThis project also includes a configuration for development using VS Code‚Äôs Remote - Containers extension.Prerequisites  Visual Studio Code  Docker Desktop  Remote - Containers extension for VS CodeSetup  Open the project folder in VS Code.  When prompted, click ‚ÄúReopen in Container‚Äù, or use the Command Palette (F1) and select ‚ÄúRemote-Containers: Reopen in Container‚Äù.  VS Code will build the dev container and reload the window with the project open inside the container.Features  Python 3.12 and Node.js 18 pre-installed  All project dependencies automatically installed  Pre-configured linting and formatting tools  Automatic port forwarding for backend (8000) and frontend (5173)  Unified development environment across different machinesUsageOnce inside the dev container:  The backend server will start automatically on port 8000.  The frontend development server will start automatically on port 5173.  You can edit files as normal, and changes will be reflected immediately due to volume mounting.  Use the integrated terminal in VS Code to run additional commands if needed.Note: The first time you open the project in the dev container, it may take a few minutes to build. Subsequent loads will be much faster.ContributingWe welcome contributions to Claude Plus! This project is in active development, and things may change rapidly and break and be buggy! Here‚Äôs how you can contribute:  Fork the repository  Create your feature branch (git checkout -b feature/AmazingFeature)  Commit your changes (git commit -m 'Add some AmazingFeature')  Push to the branch (git push origin feature/AmazingFeature)  Open a Pull RequestPlease make sure to test all your features so they do not inadvertently cause another issue.DisclaimerThis project is under active development. Features may change, and there might be bugs or unexpected behavior. Use at your own risk in production environments.Acknowledgments  Anthropic for the Claude AI model  Tavily for the search API  SearXNG for there privacy focus search  For giving me the idea for building a web version based on the ideas of a cli version https://github.com/Doriandarko/claude-engineerGithub Repohttps://github.com/bigsk1/claude-plus"
  },
  
  {
    "title": "Advanced Music Visualizer",
    "url": "/posts/Audio-Visualizer/",
    "categories": "music",
    "tags": "javascript, music, audio",
    "date": "2024-06-30 03:00:00 -0700",
    





    
    "snippet": "Advanced Music VisualizerAn advanced, interactive 3D audio visualizer using Three.js and Web Audio API. Transform your music into mesmerizing visual spectacles with a variety of shapes and color sc...",
    "content": "Advanced Music VisualizerAn advanced, interactive 3D audio visualizer using Three.js and Web Audio API. Transform your music into mesmerizing visual spectacles with a variety of shapes and color schemes. A single html file, just run in your browser.Live DemoYou can view and interact with the visualizer on Advanced Music Visualizer.Features  Visualize audio with a variety of shapes and color schemes.  Supports custom color presets.  Intensity, particle count, and rotation speed controls.  Responsive design with controls optimized for both large and small screens.How to Use  Upload an Audio File          Click on ‚ÄúChoose Audio File‚Äù and select an audio file from your device.        Select a Shape          Use the dropdown menu to choose from various shapes like Sphere, Cube, Torus, Spiral, and many more.        Control the Visuals          Intensity: Adjust the intensity of the visualization.      Particles: Adjust the number of particles in the visualization.      Rotation: Control the rotation speed of the shape.      Loop Audio: Toggle whether the audio loops.        Color Customization          Select from predefined color presets (Rainbow, Fire, Ocean, Forest) or customize your own colors.        Start, Pause, and Stop Controls          Use the Start, Pause, and Stop buttons to control the audio playback and visualization.      ShapesThe visualizer supports a variety of shapes, each providing a unique visual experience:  Sphere  Cube  Torus  Spiral  DNA  Galaxy  Fountain  Wavy Plane  Explosive Sphere  Double Helix  Donut  Nautilus Shell  Sphere Cloud  Torus Knot  Super Shape  Clifford Attractor  Ribbon Wave  Mouth  FlowerClick on the thumbnail to open the video‚òùÔ∏èBest Experience  Large Screens: The visualizer is best experienced on larger screens where you can fully appreciate the intricate details and expansive visuals.  Responsive Design: On smaller screens, the control box is hidden by default but can be toggled using the ‚ò∞ button at the top-left corner.Notes  This visualizer requires WebGL support in your browser.  The performance may vary depending on your device‚Äôs capabilities and the complexity of the visualization.AuthorCreated by bigsk1.Downloadhttps://gist.github.com/bigsk1/d2e76365c6371881c164f2f3e0e96bd4"
  },
  
  {
    "title": "Voice Chat AI",
    "url": "/posts/Voice-Chat-AI/",
    "categories": "python",
    "tags": "windows, linux, ai, voice",
    "date": "2024-06-21 03:00:00 -0700",
    





    
    "snippet": "Voice Chat AIVoice Chat AI is a project that allows you to interact with different AI characters using speech. You can choose between various characters, each with unique personalities and voices. ...",
    "content": "Voice Chat AIVoice Chat AI is a project that allows you to interact with different AI characters using speech. You can choose between various characters, each with unique personalities and voices. You can run all locally, you can use openai for chat and voice, you can mix between the two.Features  Supports both OpenAI and Ollama language models: Choose the model that best fits your needs.  Provides text-to-speech synthesis using XTTS or OpenAI TTS or ElevenLabs: Enjoy natural and expressive voices.  No typing needed, just speak: Hands-free interaction makes conversations smooth and effortless.  Analyzes user mood and adjusts AI responses accordingly: Get personalized responses based on your mood.  You can, just by speaking, have the AI analyze your screen and chat about it: Seamlessly integrate visual context into your conversations.  Easy configuration through environment variables: Customize the application to suit your preferences with minimal effort.  WebUI or Terminal usage: Can be ran with eitherInstallationRequirements  Python 3.10  CUDA-enabled GPU  Ollama models or Openai API for chat  XTTS or Openai API or ElevenLabs API for speech  Microsoft C++ Build Tools on windows  Microphone  A sense of humorSo I built this AI Speech app you can use either in the terminal or in a webui. You can talk with any character you want to make, it comes with some characters that I have made. You can see all the options to run the app in the .env file.More details here: voice-chat-ai-githubWatch the DemosClick on the thumbnail to open the video‚òùÔ∏èGPU - 100% local - ollama llama3, xtts-v2Click on the thumbnail to open the video‚òùÔ∏èCPU Only mode CLIAlien conversation using openai gpt4o and openai speech for tts.Click on the thumbnail to open the video‚òùÔ∏è"
  },
  
  {
    "title": "Nvidia CLI AI Chat",
    "url": "/posts/Nvidia-CLI-Chat/",
    "categories": "python",
    "tags": "windows, linux, ai, nvidia, gpt",
    "date": "2024-06-20 03:00:00 -0700",
    





    
    "snippet": "NVIDIA CLI ChatI bring you yet another amazing way to chat with AI, this time using nvidia NIMS! I built this terminal app to be able to test out some of the massive and state of the art LLM‚Äôs from...",
    "content": "NVIDIA CLI ChatI bring you yet another amazing way to chat with AI, this time using nvidia NIMS! I built this terminal app to be able to test out some of the massive and state of the art LLM‚Äôs from Nvidia. All you need is a free developer API key, anyone can sign up and get free credits to play around with the models.This project provides a command-line interface (CLI) chat application using various NVIDIA models through the NVIDIA API. The application allows users to interact with different language models, each with specific parameters, and have conversations directly in the terminal.Features  Supports multiple NVIDIA models with specific parameters.  Interactive chat interface using rich for better terminal formatting.  Configuration via environment variables.  API key management for secure access to NVIDIA models.Prerequisites  Python 3.6 or higher  Dev account with Nvidia (it‚Äôs free) for your API Key https://build.nvidia.com/explore/discoverInstallation      Clone the Repository:    git clone https://github.com/bigsk1/nvidia_cli_chat.gitcd nvidia_cli_chat            Create a Virtual Environment:    python3 -m venv venvsource venv/bin/activate  # On Windows use `venv\\Scripts\\activate`            Install Dependencies:    pip install -r requirements.txt            Set Up Environment Variables:    Rename .env.sample to .env:    API_KEY=\"your_single_api_key\"MISTRAL_LARGE=\"mistralai/mistral-large\"LLAMA3_70B=\"meta/llama3-70b-instruct\"PHI_3_MINI_128K=\"microsoft/phi-3-mini-128k-instruct\"ARCTIC=\"snowflake/arctic\"GRANITE_34B_CODE=\"ibm/granite-34b-code-instruct\"        Replace your_single_api_key with your actual personal NVIDIA API key. You can add additional models by just copying the models format in .env and adding them to models.py  Usage      Run the Chat Interface:    python main.py            Select a Model:    You will be prompted to select a model by number. Each model has a specific name and description to help you choose the appropriate one for your needs.        Interact with the Model:          Type your messages in the terminal.      The model will respond with generated text based on your input.            Exit the Chat:          Type exit or quit to end the chat session.      Project Structurenvidia_cli_chat/‚îú‚îÄ‚îÄ main.py                # Main script to run the chat interface‚îú‚îÄ‚îÄ api_handler.py         # Handles API requests to NVIDIA‚îú‚îÄ‚îÄ chat_interface.py      # Manages the terminal chat interface‚îú‚îÄ‚îÄ models.py              # Defines available models and their parameters‚îú‚îÄ‚îÄ .env                   # Environment variables (not included in version control)‚îú‚îÄ‚îÄ requirements.txt       # Project dependencies‚îî‚îÄ‚îÄ README.md              # Project documentationFiles Overview  main.py: The entry point of the application, which initializes the chat interface and manages the interaction loop.  api_handler.py: Contains the NvidiaAPI class that handles requests to the NVIDIA API.  chat_interface.py: Uses rich to create an interactive and formatted chat interface in the terminal.  models.py: Defines the available models, their descriptions, and parameters. Allows users to select a model at runtime.  .env: Stores environment variables including the API key and model identifiers.  requirements.txt: Lists the Python packages required to run the application.ExampleCode examples in terminalGithub RepoNvidia-CLI-Chat"
  },
  
  {
    "title": "Glance Dashboard",
    "url": "/posts/Glance/",
    "categories": "docker",
    "tags": "windows, linux, docker",
    "date": "2024-05-29 03:00:00 -0700",
    





    
    "snippet": "Glance DashboardOverviewGlance is a fast, light-weight, and highly customizable dashboard application that helps you keep all your essential information in one place. Whether you need to keep track...",
    "content": "Glance DashboardOverviewGlance is a fast, light-weight, and highly customizable dashboard application that helps you keep all your essential information in one place. Whether you need to keep track of your favorite subreddit posts, check the latest weather updates, or monitor your GitHub repositories, Glance has you covered.Key Features  Tiny but Mighty: Despite being under 15MB, Glance packs a powerful punch, offering many features without the bloat.  Parallel Processing: Glance makes all requests in parallel, ensuring you get your data as quickly as possible.  No JavaScript Frameworks: Unlike many modern web apps, Glance stays light by avoiding heavy JavaScript frameworks.  Perfect for Minimalists: If you love keeping things simple and organized, Glance is your go-to tool.  Full Customization: From themes to widgets, you can tweak nearly every aspect of Glance to suit your style and needs.Various WidgetsGlance offers a variety of widgets to cater to your information needs:  RSS feeds: Stay updated with your favorite blogs and news sources.  Subreddit posts: Keep an eye on the latest posts from your favorite subreddits.  Weather: Get weather updates and forecasts.  Bookmarks: Easily access your most frequently visited sites.  YouTube: View the latest videos from specific channels.  Calendar: Keep track of your important dates and appointments.  Stocks: Monitor stock prices and market updates.  iframe: Embed external web pages within your dashboard.  Twitch: Watch your favorite channels and keep up with top games.  GitHub releases: Stay informed about new releases from your favorite repositories.  Repository overview: Get a quick overview of your GitHub repositories.  Site monitor: Monitor the uptime and response time of your websites.ThemeableChoose from multiple color schemes to suit your style and preferences.Mobile OptimizationGlance is optimized for mobile devices, so you can access your dashboard on the go.Performance  Fast and lightweight: Minimal JavaScript and very few dependencies.  Efficient: All requests are parallelized, ensuring that uncached pages usually load within ~1 second (depending on internet speed and number of widgets).Customize!  I was able to embed a Flowise iframe into the sidebar and make a nice chatbot, directly from your Dashboard!InstallationManual Installation  Download the latest version of Glance from the releases page.  Place the binary inside /opt/glance/.  Create a systemd service to start Glance with your server. For more details, refer to this guide on creating systemd services.  To specify a different path for the config file, use the --config option:     /opt/glance/glance --config /etc/glance.yml      Docker Installation  Ensure you have a valid glance.yml file in the same directory as the Docker command.  Run the following command to start Glance in a Docker container:     docker run -d -p 8080:8080 \\   -v ./glance.yml:/app/glance.yml \\   -v /etc/timezone:/etc/timezone:ro \\   -v /etc/localtime:/etc/localtime:ro \\   glanceapp/glance        Alternatively, you can use Docker Compose:     services:   glance:     image: glanceapp/glance     volumes:       - ./glance.yml:/app/glance.yml       - /etc/timezone:/etc/timezone:ro       - /etc/localtime:/etc/localtime:ro     ports:       - 8080:8080     restart: unless-stopped      Usage InsightsGlance is designed to be a one-stop solution for all your informational needs. With its clean and customizable dashboard, you can:  Centralize Information: Aggregate data from various sources like RSS, social media, and financial markets in one place.  Stay Updated: Use it to keep track of weather updates, new releases from projects you follow, and market trends.  Enhanced Productivity: Quickly access your bookmarks, upcoming calendar events, and monitor your websites‚Äô performance, all from a single interface.  Seamless Experience: Designed to work equally well on desktop and mobile devices, ensuring you have access to your dashboard anytime, anywhere.By following the installation steps provided, you can easily set up and start using Glance to streamline your daily information digestion."
  },
  
  {
    "title": "Perplexica AI",
    "url": "/posts/Perplexica-Ai/",
    "categories": "docker",
    "tags": "windows, linux, ai",
    "date": "2024-05-28 03:00:00 -0700",
    





    
    "snippet": "Perplexica AI SearchOverviewPerplexica is an AI-powered search engine designed to enhance your search experience by delivering more accurate, context-aware results. Whether you need to find the lat...",
    "content": "Perplexica AI SearchOverviewPerplexica is an AI-powered search engine designed to enhance your search experience by delivering more accurate, context-aware results. Whether you need to find the latest news, dive into a specific subject, or keep track of your favorite topics, uses SearXNG under the hood as a meta search engine!A few points about it  AI at the Core: Perplexica utilizes advanced AI algorithms to provide smarter search results.  User-Centric Design: Built with the user in mind, Perplexica aims to be as intuitive and helpful as possible.  Community Driven: Contributions from developers worldwide help shape Perplexica‚Äôs features and improvements.  Dynamic Updates: Perplexica continuously evolves, incorporating user feedback and the latest in AI technology.  Focus Modes: Different focus modes allow you to tailor the search engine to your specific needs, whether it‚Äôs research, casual browsing, or keeping up with trends.Key FeaturesAdvanced Search CapabilitiesPerplexica goes beyond simple keyword searches by understanding the context and delivering more relevant results.Focus ModesCustomize your search experience with various focus modes:  Research: Deep dives into academic articles and detailed information.  Casual Browsing: Quick and easy searches for everyday use.  Trending Topics: Stay updated with the latest trends and news.  Personalized Results: Tag and save searches for a more personalized experience.Local LLM SupportIntegrate local Large Language Models (LLMs) to enhance your search capabilities and keep your data secure. Use your local OLLAMA install with Perplexica!ConfigurationTo learn more about configuring Perplexica, check out the project on the github Perplexica Github RepoInstallationPrerequisitesEnsure you have the following:  Node.js (for both front-end and back-end development)  Docker (optional for production setup)Backend Setup  Navigate to the root directory of the Perplexica project.  Locate the sample.config.toml file and rename it to config.toml.  Fill in the necessary configuration fields in config.toml.  Run the following command to install dependencies:     npm install        Start the backend development server:     npm run dev      Frontend Setup  Navigate to the ui directory.  Rename .env.example to .env and fill in the required frontend-specific variables.  Install frontend dependencies:     npm install        Launch the frontend development server:     npm run dev      Docker SetupFor production environments, you can use Docker to deploy Perplexica easily:  Navigate to the root directory.  Build and run the Docker containers:     docker-compose up --build      Gluetun and PerplexicaI was able to get this stack to run and work good, just need to have your VPN providers credentials, then every search or request outside your network is on a VPN.services:  gluetun:    image: qmcgaw/gluetun:latest    container_name: gluetun    cap_add:      - NET_ADMIN    devices:      - /dev/net/tun:/dev/net/tun    volumes:      - /home/user/Perplexica/gluetun:/gluetun  # in gluetun folder have servers.json    environment:      - VPN_SERVICE_PROVIDER=vpnprovidername      - OPENVPN_USER=      - OPENVPN_PASSWORD=      - SERVER_COUNTRIES=United States      - SERVER_HOSTNAMES=      - TZ=America/Phoenix      - BLOCK_MALICIOUS=on       - BLOCK_SURVEILLANCE=on       - BLOCK_ADS=on      - DOT=on      - FIREWALL_OUTBOUND_SUBNETS=192.168.1.0/24 # if using ollama at host ip of machine    networks:      - perplexica-network    ports:      - 3001:3001      - 3000:3000      - 4000:8080    restart: unless-stopped  searxng:    image: docker.io/searxng/searxng:latest    volumes:      - ./searxng:/etc/searxng:rw    network_mode: 'service:gluetun'    depends_on:      - gluetun    restart: unless-stopped  perplexica-backend:    build:      context: .      dockerfile: backend.dockerfile      args:        - SEARXNG_API_URL=http://localhost:8080  # localhost is important as it's in gluetun's network for DNS    depends_on:      - gluetun      - searxng    network_mode: 'service:gluetun'    restart: unless-stopped  perplexica-frontend:    build:      context: .      dockerfile: app.dockerfile      args:        - NEXT_PUBLIC_API_URL=http://localhost:3001/api  # if running on server and accessing from another machine add host ip of server, 192.168.x.x        - NEXT_PUBLIC_WS_URL=ws://localhost:3001  # # if running on server and accessing from another machine add host ip of server    depends_on:      - gluetun      - perplexica-backend    network_mode: 'service:gluetun'    restart: unless-stoppednetworks:  perplexica-network:Building from SourcePrerequisites  Install Node.js.  Ensure you have Docker installed for containerized production setups.Steps to Build  Clone the Perplexica GitHub repository.  Navigate to the root directory and install backend dependencies:     npm install        Navigate to the ui directory and install frontend dependencies:     cd ui &amp;&amp; npm install      Using PerplexicaGetting Started  Open your browser and go to http://localhost:3000 for the frontend interface.  Use the search bar to start exploring data with enhanced AI capabilities.  Customize your focus mode and adjust settings as needed to tailor the search experience to your needs.Perplexica Github Repo"
  },
  
  {
    "title": "Cloudflare Image Uploader",
    "url": "/posts/Cloudflare-Image-Uploader/",
    "categories": "python",
    "tags": "windows, linux, images",
    "date": "2024-02-13 02:00:00 -0800",
    





    
    "snippet": "Cloudflare Image UploaderOverviewThe Cloudflare Image Uploader is a Python script designed to automate the bulk uploading of images to Cloudflare. It handles image uploads, manages duplicates by re...",
    "content": "Cloudflare Image UploaderOverviewThe Cloudflare Image Uploader is a Python script designed to automate the bulk uploading of images to Cloudflare. It handles image uploads, manages duplicates by renaming, moves processed images to a designated directory, and generates a Markdown file listing all uploaded images for easy access and reference. This tool simplifies the management of web content images, especially for users with multiple images to upload and organize.Features  Bulk Uploads: Automatically uploads multiple images to Cloudflare in one go.  Duplicate Handling: Renames duplicate images to ensure uniqueness without overwriting existing files.  Processed Images Directory: Moves images to a ‚Äúprocessed‚Äù directory after successful upload.  Markdown Catalog Generation: Creates a .md file listing all uploaded images with URLs, making it easy to incorporate images into web content.Prerequisites  Python 3.6 or higher installed on your system.  Cloudflare account and API token with permissions to upload images.  Basic familiarity with Python and running scripts from the command line.Setup      Clone or Download the Script: Obtain the script files from the repository or download them directly to your local machine.        Install Required Python Packages:Open a terminal or command prompt and navigate to the script‚Äôs directory. Install the required packages using pip:  pip install requestsCreate a folder called Image_To_Be_Uploadedadd all the files and folder INSIDE cloudflare-image-upload folder into itOpen the upload_img_py.py file and add your detailsYour settingsAPI_TOKEN = 'your_api_token'ACCOUNT_ID = 'your_account_id'IMAGES_DIRECTORY = 'X:\\\\Cloudflare Images\\\\Image_To_Be_Uploaded'PROCESSED_DIRECTORY = 'X:\\\\Cloudflare Images\\\\Image_To_Be_Uploaded\\\\PROCESSED_DIRECTORY'CATALOG_FILE_PATH = 'X:\\\\Cloudflare Images\\\\Image_To_Be_Uploaded\\\\image_catalog.md'Edit Start_Image_upload.batadd your path to python, unsure type in CMD type:  where python add your folder path to Image_To_Be_UploadedUsageWindowsDouble click the .bat file to runLinuxpython upload_img_cf.pymarkdown fileCheck your markdown file for cloudflare url‚ÄôsExport as index.html and have all your images in a web browser to scroll through, right click to copy image url for pasting in your applications!Pro Tip use notepad + + with Markdown viewer and just click export to html, double click html to open in web browser, find your image and right click save image link ( which is the cloudflare image url! )You can use this as a visual catalog for all the images store in your cloudflare images and there sharing urlsGithubGithub Repo for cloudflare image uploader"
  },
  
  {
    "title": "Vision Image Gen Ui",
    "url": "/posts/Vision-Image-Gen/",
    "categories": "python",
    "tags": "windows, linux, streamlit",
    "date": "2024-02-03 02:00:00 -0800",
    





    
    "snippet": "AI Image GeneratorThis project leverages OpenAI‚Äôs GPT Vision and DALL-E models to analyze images and generate new ones based on user modifications. It provides two interfaces: a web UI built with S...",
    "content": "AI Image GeneratorThis project leverages OpenAI‚Äôs GPT Vision and DALL-E models to analyze images and generate new ones based on user modifications. It provides two interfaces: a web UI built with Streamlit for interactive use and a command-line interface (CLI) for direct script execution.Features  Image Analysis: Automatically describes images using GPT-4 Vision.  Image Generation: Generates modified images based on user inputs using DALL-E 3.  Web Interface: Interactive web UI for easy operation.  CLI: Command-line version for script or batch processing.How it Works:  The app first downloads the image from the provided URL or path locally and analyzes it using the pre-trained AI model gpt-4-vision-preview to generate a description.  You‚Äôre then given the opportunity to modify this description to guide the image generation process, the original description from the vision model and your included description are used.  Finally, the app uses DALL-E 3 to generate a new image 1790x1024 based on the modified description.  You can see the original image and then newly created image. Right click to save.üì∫ Watch VideoInstallationTested in Python 3.11.4Clone the repository to your local machine:git clone https://github.com/bigsk1/vision-image-gen.gitcd vision-image-genInstall the required dependencies:pip install -r requirements.txtUsageTo use the Web UITo start the web interface, run:streamlit run vision_image_gen_ui_local.pyNavigate to the URL provided by Streamlit,  http://localhost:8501, in your web browser. Enter you Open AI API Key or Have your Open Ai Api key added to your system enviroment variables in PATH  Upload an Image: Use the provided input to upload an image or specify an image URL.  View Analysis: See the AI-generated description of the image.  Modify and Generate: Enter modifications to the original description and generate a new image.  View and Save: The generated image will be displayed, and you can save it locally.CLI VersionThe CLI version allows you to process images directly from your terminal.python vision_image_gen.pyUsing Streamlit Cloud SharingUse the vision_image_gen_ui.py for Streamlit Cloud sharing, in the settings just add[openai]api_key = \"sk-paste-your-api-key\"the ui and ui_local are basiclly the same file but the api functions differently due to streamlit‚Äôs setupExample of output==================================================Vision Response:==================================================The image shows a computer terminal interface with ASCII art and text. At the top would be ASCII art resembling a face with a pattern of \"#\" and \".\" characters. Below it, within a minimalist window frame, is a navigation menu with options depicted as a pixel-style globe icon labeled \"sumfetch,\" a document icon labeled \"ABOUT,\" a link icon labeled \"Website,\" a folder icon labeled \"This Repo,\" and a series of contact methods including an email address, GitHub URL, and Twitter handle, all associated with the username \"bigsk1\". The central feature is a bold ASCII art logo or emblem saying \"BIGSK1\" inside a stylized circular border.For a text-to-image model, you could describe it as follows:\"Create an image of a dark computer terminal screen with a pixelated face made out of ASCII characters at the top. Include a stylized ASCII art logo that says 'BIGSK1' in the center, enclosed in a circular patterned border. Below the logo, depict a simple user interface with text and monochrome icons signifying navigation options, including a globe for 'sumfetch,' a document for 'ABOUT,' a link chain for 'Website,' and a folder for 'This Repo.' Add additional details==================================================User's Modification Input:==================================================make it in the style of an american flag==================================================Final Prompt Sent to DALL-E 3:==================================================The image shows a computer terminal interface with ASCII art and text. At the top would be ASCII art resembling a face with a pattern of characters. Below it, within a minimalist window frame, is a navigation menu with options depicted as a pixel-style globe icon labeled \"sumfetch,\" a document icon labeled \"ABOUT,\" a link icon labeled \"Website,\" a folder icon labeled \"This Repo,\" and a series of contact methods including an email address, GitHub URL, and Twitter handle, all associated with the username \"bigsk1\". The central feature is a bold ASCII art logo or emblem saying \"BIGSK1\" inside a stylized circular border.For a text-to-image model, you could describe it as follows:\"Create an image of a dark computer terminal screen with a pixelated face made out of ASCII characters at the top. Include a stylized ASCII art logo that says 'BIGSK1' in the center, enclosed in a circular patterned border. Below the logo, depict a simple user interface with text and monochrome icons signifying navigation options, including a globe for 'sumfetch,' a document for 'ABOUT,' a link chain for 'Website,' and a folder for 'This Repo.' Add additional details make it in the style of an american flagExample image in the original_image folder this is were your downloaded images will end up.The generated_images folder is were the new Dalle generated image will end up.This is a work in progress, more to add soon."
  },
  
  {
    "title": "Matrix Crypto Terminal",
    "url": "/posts/Matrix-Crypto/",
    "categories": "python",
    "tags": "windows, linux, bitcoin, crypto, terminal",
    "date": "2024-02-03 02:00:00 -0800",
    





    
    "snippet": "Matrix Crypto Terminal Display üíªThe Matrix Crypto Display is a Python-based terminal application that provides a visually appealing display of cryptocurrency information in a matrix-style animation...",
    "content": "Matrix Crypto Terminal Display üíªThe Matrix Crypto Display is a Python-based terminal application that provides a visually appealing display of cryptocurrency information in a matrix-style animation. This project offers two main functionalities: one version displays real-time cryptocurrency prices, and another displays cryptocurrency names without prices for a simplified, aesthetic experience.Features  Real-time Price Updates: Fetch and display the latest cryptocurrency prices in real-time. Uses coingecko public api to get prices every 90 seconds  Cryptocurrency Name Display: A no-prices version that focuses on displaying the names of cryptocurrencies.  Customizable Display: Users can customize the display speed and color to suit their preferences.  Flexible Configuration: Easy configuration through JSON files to specify which cryptocurrencies to display.  Command-line Options: Includes options for adjusting display settings directly through command-line arguments.  Custom scripts for getting latest crypto ecosystem lists, Top 20 Solana or Ethereum tokensüì∫ Watch VideoDownload python if you don‚Äôt already have itPython DownloadInstallationClone the Repositorygit clone https://github.com/bigsk1/matrix-crypto.gitcd matrix-cryptoQuick startWindowsDouble click the run_windows.bat fileIf having trouble, Windows users might need to manually download and use Miniconda with python=3.11.4 and run:pip install -r requirements.txtLinux/MacOSchmod +x run_linux.sh &amp;&amp; ./run_linux.shIf you have trouble running then run:sed -i 's/\\r$//' ./run_linux.shAnd try again:./run_linux.shManual InstallCreate and Activate a Virtual Environment (Optional but Recommended)python -m venv venvsource venv/bin/activate  # On Windows use `venv\\Scripts\\activate`Install Required Packagespip install -r requirements.txtUsagepython matrix_crypto.pyCTL+C to ExitAdd to bashrc or zshrc ( optional for linux )Want to type matrixc and start the script? cmatrix but for crypto!!!Ensure your script is executable. Navigate to the directory where your matrix_crypto.py script is located and run:chmod +x matrix_crypto.pyOpen your .zshrc or .bashrc file in a text editor and update your path:alias matrixc='cd /path/to/matrix-crypto &amp;&amp; python matrix_crypto.py'Replace /path/to/matrix-crypto/matrix_crypto.py with the actual path to your script.source ~/.zshrcNow you can run your script from anywhere in the terminal by typing:matrixcAdvanced UsageRun the application:python matrix_crypto.py [--bg-color BG_COLOR] [--crypto-color CRYPTO_COLOR] [--solana] [--eth]Command-line Options  ‚Äìbg-color: Adjust the color of the falling background text (e.g., green, red, blue).  ‚Äìcrypto-color: Choose the color of the crypto tickers (e.g., white, yellow, cyan).  ‚Äìsolana, ‚Äìeth: Use a specific cryptocurrency list (e.g., Solana or Ethereum ecosystems).Example:python matrix_crypto.py --bg-color red --crypto-color yellow --ethUpdate crypto ecosystem listUse the prefilled crypto_list.json or modify and add your own tickers.(Optional) You can run any of the .py files to get the current list of Solana or Ethereum top 20 to populate the .json config, which is to get token IDs and names for prices. Only really need to run once in a while if you want a fresh list. I would remove stable coins like USDC and USDT.  python crypto_list.py: Gets top 20 overall cryptos by market cap (default list of cryptos).  python solana_crypto_list.py: Gets top 20 Solana tokens by market cap.  python ethereum_crypto_list.py: Gets top 20 Ethereum tokens by market cap.ConfigurationEdit the crypto_list.json file for the name display version or the respective ecosystem files (e.g., solana_ecosystem_crypto_list.json) for the price display version to customize which cryptocurrencies are shown.Example configuration for name display:{    \"cryptos\": [        {            \"id\": \"bitcoin\",            \"ticker\": \"BTC\",            \"name\": \"Bitcoin\"        },        {            \"id\": \"ethereum\",            \"ticker\": \"ETH\",            \"name\": \"Ethereum\"        }    ]}Customizing the Cryptocurrency ListTo modify the list of displayed cryptocurrencies, edit the appropriate .json configuration file by adding or removing entries under the ‚Äúcryptos‚Äù key.Settings changesYou can directly change settings in the maxtrix_crypto.py file to fine tune the look your after!# User-configurable settingsSETTINGS = {    'ANIMATION_SPEED': 0.01,  # Lower is faster, higher is slower. This is the delay between frames in seconds.    'BACKGROUND_PATTERN': [1, 2, 3, 2],  # Gap widths pattern.    'BACKGROUND_CHARS': 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789!@#$%^&amp;*()_+-=[]{}|;:,.&lt;&gt;?/',    'CRYPTO_DISPLAY_COUNT': 4,  # Maximum number of crypto prices displayed simultaneously.    'CRYPTO_DISPLAY_CHANCE': 0.1,  # Chance of new crypto display appearing each frame.    'FADE_LENGTH': 0,  # Length of fade effect at top and bottom in number of characters.    'BACKGROUND_INTENSITY_LEVELS': 3,  # Number of intensity levels for background.    'CRYPTO_FALL_SPEED_RANGE': (0.1, 0.2),  # Min and max fall speed for crypto displays in seconds.    'BACKGROUND_CHANGE_CHANCE': 0.2,  # Chance of a background character changing each update.    'BACKGROUND_FALL_SPEED_RANGE': (0.06, 0.1),  # Min and max fall speed for background characters in seconds.    'BACKGROUND_COLUMN_LENGTH_RANGE': (0.3, 0.7),  # Min and max length of background columns as a fraction of screen height.    'BACKGROUND_COLUMN_GAP_RANGE': (0.2, 0.3),  # Min and max gap between columns as a fraction of screen height.    'LEAD_CHAR_COLOR': curses.COLOR_WHITE,  # Color of the leading character in each column.    'LEAD_CHAR_CHANCE': 1,  # Chance of a new leading character appearing when the column updates.    'CRYPTO_COLOR': 'white',  # Default color for crypto tickers}LoggingThe application generates a log file (matrix_crypto.log) to store runtime information, errors, and other log messages. The log is rotated every 10 days to prevent excessive file size.Cryptocurrency Name Display OnlyRun the simplified version that displays only cryptocurrency names under the offline-version-no-prices folder:python matrix_crypto.py [--bg-color BG_COLOR] [--crypto-color CRYPTO_COLOR]Sample Command-Line CombinationsBelow are some sample command-line combinations you can use to run the matrix_crypto.py script with various options. Each command is provided in a code block for easy copying.Default Run (without any arguments)python matrix_crypto.pyCustom Background Color  Green background (default)    python matrix_crypto.py --bg-color green        Red background    python matrix_crypto.py --bg-color red        Blue background    python matrix_crypto.py --bg-color blue        Yellow background    python matrix_crypto.py --bg-color yellow      Custom Crypto Ticker Color  White ticker (default)    python matrix_crypto.py --crypto-color white        Yellow ticker    python matrix_crypto.py --crypto-color yellow        Cyan ticker    python matrix_crypto.py --crypto-color cyan        Magenta ticker    python matrix_crypto.py --crypto-color magenta      Using Different Crypto Lists  Use Solana ecosystem crypto list    python matrix_crypto.py --solana        Use Ethereum ecosystem crypto list    python matrix_crypto.py --eth      Combination of Arguments  Red background with yellow ticker and Solana crypto list    python matrix_crypto.py --bg-color red --crypto-color yellow --solana        Blue background with cyan ticker and Ethereum crypto list    python matrix_crypto.py --bg-color blue --crypto-color cyan --eth        Green background with magenta ticker and Solana crypto list    python matrix_crypto.py --bg-color green --crypto-color magenta --solana      Additional Custom Combinations  Yellow background with white ticker    python matrix_crypto.py --bg-color yellow --crypto-color white        Cyan background with red ticker    python matrix_crypto.py --bg-color cyan --crypto-color red        Magenta background with blue ticker    python matrix_crypto.py --bg-color magenta --crypto-color blue      "
  },
  
  {
    "title": "File Converter",
    "url": "/posts/File-Converter/",
    "categories": "windows",
    "tags": "windows, images, docs",
    "date": "2024-01-22 02:00:00 -0800",
    





    
    "snippet": "File Converter for WindowsFile Converter is a versatile and free tool for Windows that simplifies the process of file conversion and compression. It integrates seamlessly into the Windows Explorer ...",
    "content": "File Converter for WindowsFile Converter is a versatile and free tool for Windows that simplifies the process of file conversion and compression. It integrates seamlessly into the Windows Explorer context menu, offering quick and easy access to its features.Key Features  Wide Range of Formats: Supports numerous file formats, including audio, video, image, and document files.  Customizable: Users can add, remove, or modify conversion presets.  Integration: Offers integration with Windows Explorer for convenience.  Requirement: Needs Microsoft Office for converting Office documents.  License: Available as an open source project under GPL v3.UsageUsers can right-click on files in Windows Explorer to access File Converter‚Äôs options for converting or compressing files.Download and More InformationFor more details and to download, visit the official website.üì∫ Watch VideoGithubhttps://github.com/Tichau/FileConverter"
  },
  
  {
    "title": "Docker for AI Development",
    "url": "/posts/Docker-Dev-Container/",
    "categories": "docker",
    "tags": "windows, wsl, linux, ai, docker, docs",
    "date": "2024-01-22 02:00:00 -0800",
    





    
    "snippet": "Docker-Based Nvidia / Python / Node Development Environment üíªDocker is an amazing tool that lets you create isolated environments called ‚Äúcontainers‚Äù for your development projects. Think of it like...",
    "content": "Docker-Based Nvidia / Python / Node Development Environment üíªDocker is an amazing tool that lets you create isolated environments called ‚Äúcontainers‚Äù for your development projects. Think of it like having a tiny, fully-functional computer inside your main computer where you can play around, build things, and not worry about messing up your main system.Why Use Docker for Development?  Isolation: Each project can have its own environment with specific tools and versions, without affecting other projects.  Consistency: The environment is consistent, so it works the same way on everyone‚Äôs computer.  Simplicity: Easy to share and replicate environments, making collaboration smoother.  Safety: Experiment without risking your main system.Example Projects  Web Development: Perfect for building web apps using technologies like Node.js, Python Flask, or Ruby on Rails.  Data Science: Great for data projects using Jupyter Notebooks with Python, R, or Julia.  Machine Learning: Ideal for machine learning projects using TensorFlow, PyTorch, and CUDA for GPU support.  Note: Create a folder that we will use to map from your host computer to inside the docker container. So when you are working inside the container your work can be saved inside this mapped folder, the examples below we call it workspaceWho is this for?  Using linux or Windows (wsl) with Nvidia RTX GPU and want a dev enviroment  Install projects like Stable Diffusion, ComfyUI, Oobabooga Text Gen Webui or other GPU required local LLM in isolation  Looking to build using Python, Node.js and might want to be able to use your Nvidia GPU on projects and want an isolated enviroment, one that can be removed and another started quickly.  Music or Voice generation using GPU acceleration, like MusicGen, AudioGen, Bark or Whisper  Building an AI App with AI Agents doing tasks on your file system, keep em caged up so they don‚Äôt mess something up.Works well with  VScode  - you can comment out the vs-code server in Dockerfile to add a locally running web based version or use your own vscode with it  Docker Desktop to manage image and container.  Portainer, Dockage or other docker managment systems  In WSL Ubuntu or DebianCreate a DockerfileSo I am going to show a Dockerfile I use as a general purpose work enviroment. It is for those using Nvidia GPU‚Äôs and any kind of AI work like with Stable Diffusion or running a local LLM. This container is about 20GB so just be aware. Also change the ENV timezone to your timezone in the DockerfileWhat does this Dockerfile do?Base Image: NVIDIA CUDA on Ubuntu  NVIDIA CUDA Toolkit: Your Docker image is based on an NVIDIA CUDA image (nvidia/cuda:12.3.1-devel-ubuntu22.04), which includes the CUDA Toolkit. CUDA (Compute Unified Device Architecture) is a parallel computing platform and API model created by NVIDIA. It allows software developers to use a CUDA-enabled graphics processing unit (GPU) for general purpose processing (an approach termed GPGPU, General-Purpose computing on Graphics Processing Units).  Ubuntu 22.04: This is a Linux distribution based on Debian, known for its reliability and ease of use. It‚Äôs a popular choice for development environments.Programming Languages and Tools  Python 3.11: A high-level, interpreted programming language known for its readability and wide range of applications in web development, data science, artificial intelligence, and more. Also includes the nightly pytorch version 12.1  Node.js: An open-source, cross-platform, back-end JavaScript runtime environment that executes JavaScript code outside a web browser.  JupyterLab: An interactive development environment for Jupyter notebooks, code, and data. It‚Äôs widely used in data science for its ease of plotting and data manipulation.Development Tools  Git: A distributed version-control system for tracking changes in source code during software development.  Curl: A command-line tool for transferring data with URLs, used in scripts or for testing APIs.  Vim and Nano: Text editors in the Linux environment. Vim is known for its efficiency and powerful features, while Nano is appreciated for its simplicity.Additional Packages  Build-Essential: A package that includes compilers and libraries essential for compiling software. It typically includes GCC/g++, make, and other utilities.  FFmpeg: A complete, cross-platform solution to record, convert, and stream audio and video.Configuration  Timezone Setting: You can set the timezone to your preferred region, which is important for logs, scheduled tasks, and time-sensitive applications.Docker Container Features  Volume Mounting: The ability to mount a directory from your host machine to the Docker container, ensuring data persistence and easy file access.  Port Mapping: Exposing specific ports for services like JupyterLab to be accessible from the host machine.DockerfileThis Docker image provides a robust, isolated development environment with support for GPU-accelerated applications, making it ideal for a wide range of projects from web development to machine learning. With the inclusion of JupyterLab, it‚Äôs also well-suited for interactive data exploration and analysis.# Use an NVIDIA CUDA developer image based on Ubuntu 22.04FROM nvidia/cuda:12.3.1-devel-ubuntu22.04# Set the timezone to America/Los_AngelesENV TZ=America/Los_AngelesRUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime &amp;&amp; echo $TZ &gt; /etc/timezone# Install necessary packagesRUN apt-get update &amp;&amp; apt-get install -y \\    software-properties-common \\    build-essential \\    git \\    curl \\    vim \\    nano \\    wget \\    libffi-dev \\    libssl-dev \\    libbz2-dev \\    libreadline-dev \\    libsqlite3-dev \\    llvm \\    xz-utils \\    tk-dev \\    libncurses5-dev \\    libncursesw5-dev \\    zlib1g-dev \\    ffmpeg # Adding FFmpeg# Install Python 3.11 from sourceRUN wget https://www.python.org/ftp/python/3.11.0/Python-3.11.0.tar.xz &amp;&amp; \\    tar -xf Python-3.11.0.tar.xz &amp;&amp; \\    cd Python-3.11.0 &amp;&amp; \\    ./configure --enable-optimizations &amp;&amp; \\    make -j 8 &amp;&amp; \\    make altinstall# Upgrade pip for Python 3.11RUN python3.11 -m pip install --upgrade pip# Set Python 3.11.0 as the default Python versionRUN ln -sf /usr/local/bin/python3.11 /usr/bin/python3 &amp;&amp; \\    ln -sf /usr/local/bin/python3.11 /usr/bin/python# Install PyTorchRUN python3.11 -m pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu121# Install additional Python toolsRUN python3.11 -m pip install jupyterlab# Install Node.js (Current Version)RUN curl -fsSL https://deb.nodesource.com/setup_current.x | bash - &amp;&amp; \\    apt-get install -y nodejs# Install code-server (VSCode server) - optional if using Remote - Containers# RUN curl -fsSL https://code-server.dev/install.sh | sh# Clean up APT when doneRUN apt-get update &amp;&amp; apt-get upgrade -y &amp;&amp; apt-get clean &amp;&amp; rm -rf /var/lib/apt/lists/*# Set the working directoryWORKDIR /workspace# Set up JupyterLab (optional, but useful for a dev environment)EXPOSE 8888# Expose port for code-server (optional)# EXPOSE 8080# Default command (can be overridden)CMD [\"/bin/bash\"]Build Your Docker ImageNext, you build a Docker image from your Dockerfile. This image is like a snapshot of your environment. Run the command in the same directory as your Dockerfiledocker build -t dev_work .Use this command to start the container and keep it running. Make sure to add your correct path to your workspace folder. Type pwd in your terminal if unsure.docker run -it \\           --gpus all \\           --name dev_work_container \\           --restart unless-stopped \\           -v /home/path/to/your/workspace:/workspace \\           -p 8888:8888 \\           dev_work \\           tail -f /dev/nullTo get inside the container and rundocker exec -it dev_work_container /bin/bashThat‚Äôs it your in, find your workspace folder and inside you can make a new folder for each project you like to work on, also you can just run another container from same image just change the name of it in docker run command like dev_work_container2 , ect..When inside the container if you want to use a jupyter notebook server use the below commandjupyter-lab --ip=0.0.0.0 --allow-root --NotebookApp.token='' --port=8888I like to use the above because I can use Docker Desktop on windows to stop and start the container at anytime, like only when I want to use it, and the jupyter service isn‚Äôt running full time. Also when you stop the jupyter service your container doesn‚Äôt stop. You don‚Äôt need jupyter it is optional and up to you but can come in handy running cells.Open in VSCodeInstall the Microsoft Remote Development extention pack. Then ctl+shift+P and type in:  Dev Containers: Attach to running container. Boom your in.Inside the dev_work container type nvidia-smi you should see something similar to let you know your GPU is available to be used.+---------------------------------------------------------------------------------------+| NVIDIA-SMI 545.37.02              Driver Version: 546.65       CUDA Version: 12.3     ||-----------------------------------------+----------------------+----------------------+| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC || Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. ||                                         |                      |               MIG M. ||=========================================+======================+======================||   0  NVIDIA GeForce RTX 4090        On  | 00000000:01:00.0  On |                  Off ||  0%   38C    P8              20W / 450W |   1239MiB / 24564MiB |      1%      Default ||                                         |                      |                  N/A |+-----------------------------------------+----------------------+----------------------+                                                                                         +---------------------------------------------------------------------------------------+| Processes:                                                                            ||  GPU   GI   CI        PID   Type   Process name                            GPU Memory ||        ID   ID                                                             Usage      ||=======================================================================================||  No running processes found                                                           |+---------------------------------------------------------------------------------------+If you don‚Äôt see the above make sure your host has the latest Nvidia driversCUDA Toolkit in the Container: The CUDA Toolkit, included in the NVIDIA Docker image, is a collection of tools, libraries, and APIs that enable developers to create software that can perform computations on the GPU. This toolkit inside the container works seamlessly with the host‚Äôs NVIDIA drivers.Here is a breakdown of the Nvidia Image that is used when building this Dockerfile:      CUDA Toolkit: This is the primary feature of the image. The CUDA Toolkit includes the CUDA runtime and development libraries needed to develop CUDA-enabled applications. It‚Äôs essential for writing and running software that directly interfaces with the GPU for parallel processing tasks.        cuDNN (CUDA Deep Neural Network Library): Some of the NVIDIA CUDA images include cuDNN, which is a GPU-accelerated library for deep neural networks. cuDNN is used extensively in deep learning frameworks like TensorFlow and PyTorch.        Other CUDA Libraries: Depending on the specific image, it might also include additional CUDA libraries like cuBLAS (for linear algebra operations), cuFFT (for Fast Fourier Transforms), and others. These libraries provide optimized GPU implementations of standard algorithms which are widely used in scientific computing and machine learning.        Compatibility with NVIDIA Drivers: These images are designed to work with the NVIDIA drivers installed on your host machine. The container uses the host‚Äôs GPU resources through NVIDIA‚Äôs runtime and drivers.  You can always search for another type of Nvidia Image on the hub and replace it in the Dockerfile!  https://hub.docker.com/r/nvidia/cuda/tagsPytorch usage** During the image build we switch to using Python 3.11.0 instead of Nvidia‚Äôs prebuilt image with python 3.10.12. However you have the option to use python 3.10.12 also if you like however in testing pytorch doesn‚Äôt seem to work with it so by default we enabled 3.11.0.To test you can use in jupyter notebook or in terminal in your contrainer ‚Äúpython‚Äù and then paste the codeimport torchprint(\"PyTorch Version:\", torch.__version__)print(\"CUDA Available:\", torch.cuda.is_available())print(\"CUDA Version:\", torch.version.cuda)print(\"Number of GPUs:\", torch.cuda.device_count())You should get back if working correctly  PyTorch Version: 2.3.0.dev20240122+cu121  CUDA Available: True  CUDA Version: 12.1  Number of GPUs: 1import torchprint(torch.version.cuda)print(torch.cuda.is_available())  12.1  TrueYou can also make a python file call pytorch_test.py# pytorch_test.pyimport torchdef test_pytorch_cuda():    # Check if CUDA is available    if torch.cuda.is_available():        print(\"CUDA is available. Testing with a simple operation.\")        # Create a random tensor        x = torch.rand(5, 3)        print(\"Original Tensor:\\n\", x)        # Move the tensor to GPU        x = x.cuda()        print(\"Tensor on CUDA:\\n\", x)        # Perform a simple addition operation        y = x + 1        print(\"Tensor after addition:\\n\", y)        print(\"PyTorch and CUDA are working correctly!\")    else:        print(\"CUDA is not available. Please check your installation.\")if __name__ == \"__main__\":    test_pytorch_cuda()and running the commandpython3 pytorch_test.pyCUDA is available. Testing with a simple operation.Original Tensor: tensor([[0.8696, 0.6349, 0.9674],        [0.4257, 0.2892, 0.3230],        [0.9859, 0.4811, 0.2655],        [0.2030, 0.1596, 0.3838],        [0.9341, 0.3455, 0.1313]])Tensor on CUDA: tensor([[0.8696, 0.6349, 0.9674],        [0.4257, 0.2892, 0.3230],        [0.9859, 0.4811, 0.2655],        [0.2030, 0.1596, 0.3838],        [0.9341, 0.3455, 0.1313]], device='cuda:0')Tensor after addition: tensor([[1.8696, 1.6349, 1.9674],        [1.4258, 1.2892, 1.3230],        [1.9859, 1.4811, 1.2655],        [1.2030, 1.1596, 1.3838],        [1.9341, 1.3455, 1.1313]], device='cuda:0')PyTorch and CUDA are working correctly!Tensorflowhttps://www.tensorflow.org/install/pipIf needed you can install tensorflow with GPU usepip install tensorflowand then check was installed correctlypython3 -c \"import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))\"Githubhttps://github.com/bigsk1/dev_work"
  },
  
  {
    "title": "Windows Sandbox",
    "url": "/posts/Windows-Sandbox/",
    "categories": "windows",
    "tags": "windows, docs",
    "date": "2024-01-19 02:00:00 -0800",
    





    
    "snippet": "Windows Sandbox enviroment inside of WindowsWindows Sandbox (WSB) is a lightweight virtual machine environment designed to safely run applications in isolation from the main operating system. This ...",
    "content": "Windows Sandbox enviroment inside of WindowsWindows Sandbox (WSB) is a lightweight virtual machine environment designed to safely run applications in isolation from the main operating system. This feature, available in Windows 10 and Windows 11 Pro, Enterprise, and Education editions, offers several advantages and use cases:Descriptions and Advantages of Windows Sandbox (WSB):      Isolation: WSB provides a temporary, isolated environment. Anything you do inside the sandbox does not affect your main operating system, ensuring safety and cleanliness.        Security: It‚Äôs an ideal solution for safely running untrusted or untested software. If the software turns out to be malicious or unstable, it won‚Äôt harm your main system.        Testing and Development: Developers or testers can use WSB to test applications, scripts, or even new settings without risking their primary system configuration.        Ease of Use: Unlike traditional virtual machines, WSB is quick to set up and requires no separate license. It uses a small amount of your system‚Äôs resources and is disposed of once closed.        Clean Environment: Each time WSB is started, it provides a clean, brand-new installation of Windows. This is particularly useful for testing software under default conditions.        Snapshot and Clipboard Sharing: While isolated, WSB allows for clipboard sharing and taking snapshots, making it easier to move information in and out of the sandbox.  Practical Use Case:Scenario: Suppose you‚Äôre a developer who needs to test a new software update but doesn‚Äôt want to risk the stability of your primary system or deal with the overhead of a full-fledged VM.Solution with WSB: You can use Windows Sandbox to create an isolated environment where you can install and run the new software. This approach allows you to monitor how the software behaves, test its features, and even intentionally try to break it to see how it handles errors, all without any risk to your actual operating system. If anything goes wrong, you simply close the sandbox, and everything is reset to a clean state for your next test.Integration with Blog Code Examples:In your blog, you can include specific examples of how to use Windows Sandbox for common tasks, like installing new software, testing scripts, or even how to configure the sandbox environment (like network settings or shared folders). Real-world examples will help your readers understand the practical benefits and how to implement them in their workflows.Examples I useReplace the location of your host folder in these examples. You can name these files what ever you like but make sure you put the file extention as a .wsb like ( sandbox_shared.wsb ) Make sure to add a folder that already existing on your system. Create the file and then doubleclick it! It‚Äôs that simple. Once you are done with it and close it, it is destroyed so if you want to keep anything between the sandbox and host system make sure host folder path is mapped.Sandbox for a Shared Enviroment&lt;Configuration&gt;    &lt;MappedFolders&gt;        &lt;MappedFolder&gt;            &lt;HostFolder&gt;Y:\\win_sandbox_shared_folder&lt;/HostFolder&gt;            &lt;ReadOnly&gt;false&lt;/ReadOnly&gt;        &lt;/MappedFolder&gt;    &lt;/MappedFolders&gt;&lt;/Configuration&gt;No Networking with Protections Enabled&lt;Configuration&gt;    &lt;MappedFolders&gt;        &lt;MappedFolder&gt;            &lt;HostFolder&gt;Y:\\win_sandbox_shared_folder&lt;/HostFolder&gt;            &lt;ReadOnly&gt;true&lt;/ReadOnly&gt;        &lt;/MappedFolder&gt;    &lt;/MappedFolders&gt;\t&lt;ProtectedClient&gt;Enable&lt;/ProtectedClient&gt;\t&lt;Networking&gt;Disable&lt;/Networking&gt;&lt;/Configuration&gt;No Networking -  Protections Enabled -  No clipboard&lt;Configuration&gt;    &lt;MappedFolders&gt;        &lt;MappedFolder&gt;            &lt;HostFolder&gt;Y:\\win_sandbox_shared_folder&lt;/HostFolder&gt;            &lt;ReadOnly&gt;true&lt;/ReadOnly&gt;        &lt;/MappedFolder&gt;    &lt;/MappedFolders&gt;\t&lt;ProtectedClient&gt;Enable&lt;/ProtectedClient&gt;\t&lt;Networking&gt;Disable&lt;/Networking&gt;\t&lt;ClipboardRedirection&gt;Disable&lt;/ClipboardRedirection&gt;\t&lt;PrinterRedirection&gt;Disable&lt;/PrinterRedirection&gt;\t&lt;AudioInput&gt;Disable&lt;/AudioInput&gt;\t&lt;vGPU&gt;Disable&lt;/vGPU&gt;&lt;/Configuration&gt;Protected Client -  Read Only with Networking&lt;Configuration&gt;    &lt;MappedFolders&gt;        &lt;MappedFolder&gt;            &lt;HostFolder&gt;Y:\\win_sandbox_shared_folder&lt;/HostFolder&gt;            &lt;ReadOnly&gt;true&lt;/ReadOnly&gt;        &lt;/MappedFolder&gt;    &lt;/MappedFolders&gt;\t&lt;ProtectedClient&gt;Enable&lt;/ProtectedClient&gt;&lt;/Configuration&gt;Explanation of each option&lt;Configuration&gt;    &lt;MappedFolders&gt;        &lt;MappedFolder&gt;            &lt;HostFolder&gt;Y:\\win_sandbox_shared_folder&lt;/HostFolder&gt;            &lt;!-- HostFolder: Specifies the path to the folder on your host machine to be shared with the sandbox. --&gt;            &lt;ReadOnly&gt;true&lt;/ReadOnly&gt;            &lt;!-- ReadOnly: When set to true, the sandbox can view but not modify the contents of the shared folder. --&gt;        &lt;/MappedFolder&gt;    &lt;/MappedFolders&gt;    &lt;!-- MappedFolders: Defines one or more folders shared between the host and the sandbox. --&gt;    &lt;ProtectedClient&gt;Enable&lt;/ProtectedClient&gt;    &lt;!-- ProtectedClient: If enabled, makes the sandbox operate as a protected client, enhancing security. --&gt;    &lt;Networking&gt;Disable&lt;/Networking&gt;    &lt;!-- Networking: Disables network access in the sandbox, isolating it from the internet and local network. --&gt;    &lt;ClipboardRedirection&gt;Disable&lt;/ClipboardRedirection&gt;    &lt;!-- ClipboardRedirection: Disables sharing of clipboard content between the host and the sandbox. --&gt;    &lt;PrinterRedirection&gt;Disable&lt;/PrinterRedirection&gt;    &lt;!-- PrinterRedirection: Disables the ability of the sandbox to access printers configured on the host. --&gt;    &lt;AudioInput&gt;Disable&lt;/AudioInput&gt;    &lt;!-- AudioInput: Disables the sandbox's access to the host's microphone and other audio input devices. --&gt;    &lt;vGPU&gt;Disable&lt;/vGPU&gt;    &lt;!-- vGPU: Disables virtualized GPU support, which affects the ability to run graphics-intensive applications. --&gt;&lt;/Configuration&gt;Additional Configurable OptionsMemoryInMB: Sets the amount of memory (RAM) in megabytes that the sandbox can use.    Example: &lt;MemoryInMB&gt;2048&lt;/MemoryInMB&gt;    Note: This tag sets the sandbox to use 2 GB of RAM.LogonCommand: Defines a command that will run automatically when the sandbox starts.    Example: &lt;LogonCommand&gt;&lt;Command&gt;start msedge.exe&lt;/Command&gt;&lt;/LogonCommand&gt;    Note: This command will automatically open Microsoft Edge when the sandbox starts.VideoInput: Enables or disables access to the host's webcam.    Example: &lt;VideoInput&gt;Disable&lt;/VideoInput&gt;    Note: Disables the sandbox's access to the host's webcam.EnableClipboardSharing: Allows sharing of clipboard content between the host and the sandbox.    Example: &lt;EnableClipboardSharing&gt;true&lt;/EnableClipboardSharing&gt;    Note: Enables clipboard sharing, contrary to ClipboardRedirection.AudioOutput: Controls whether the sandbox can play sound.    Example: &lt;AudioOutput&gt;Enable&lt;/AudioOutput&gt;    Note: Enables the sandbox to play sounds using the host's audio devices.Example of a Highly Configurable .wsb File&lt;Configuration&gt;    &lt;MappedFolders&gt;        &lt;MappedFolder&gt;            &lt;HostFolder&gt;C:\\Path\\To\\Shared\\Folder&lt;/HostFolder&gt;            &lt;ReadOnly&gt;false&lt;/ReadOnly&gt;        &lt;/MappedFolder&gt;    &lt;/MappedFolders&gt;    &lt;MemoryInMB&gt;4096&lt;/MemoryInMB&gt;    &lt;LogonCommand&gt;&lt;Command&gt;start explorer.exe&lt;/Command&gt;&lt;/LogonCommand&gt;    &lt;ProtectedClient&gt;Enable&lt;/ProtectedClient&gt;    &lt;Networking&gt;Enable&lt;/Networking&gt;    &lt;ClipboardRedirection&gt;Enable&lt;/ClipboardRedirection&gt;    &lt;PrinterRedirection&gt;Enable&lt;/PrinterRedirection&gt;    &lt;AudioInput&gt;Enable&lt;/AudioInput&gt;    &lt;AudioOutput&gt;Enable&lt;/AudioOutput&gt;    &lt;VideoInput&gt;Enable&lt;/VideoInput&gt;    &lt;vGPU&gt;Enable&lt;/vGPU&gt;&lt;/Configuration&gt;This configuration sets up a Windows Sandbox with shared folders, ample memory, useful automatic startup commands, and full access to networking, clipboard, printers, audio, video, and GPU resources. Remember to adjust paths and settings according to your needs.Start sandbox - download firefox and install itFirst make a script and add to Host Folder, call it firefox_download.bat@echo offPowerShell -Command \"Invoke-WebRequest -Uri 'https://download.mozilla.org/?product=firefox-latest-ssl&amp;os=win64&amp;lang=en-US' -OutFile 'FirefoxInstaller.exe'\"start FirefoxInstaller.exe /silent /installthen add a LogonCommand to your .wsb to run the batch script&lt;LogonCommand&gt;    &lt;Command&gt;C:\\Users\\WDAGUtilityAccount\\Desktop\\SharedFolder\\firefox_download.bat&lt;/Command&gt;&lt;/LogonCommand&gt;Complete .wsb Configuration ExampleAdd your Host Folder path&lt;Configuration&gt;    &lt;MappedFolders&gt;        &lt;MappedFolder&gt;            &lt;HostFolder&gt;C:\\Path\\To\\Shared\\Folder&lt;/HostFolder&gt;            &lt;ReadOnly&gt;false&lt;/ReadOnly&gt;        &lt;/MappedFolder&gt;    &lt;/MappedFolders&gt;    &lt;Networking&gt;Enable&lt;/Networking&gt;    &lt;LogonCommand&gt;        &lt;Command&gt;C:\\Users\\WDAGUtilityAccount\\Desktop\\SharedFolder\\firefox_download.bat&lt;/Command&gt;    &lt;/LogonCommand&gt;&lt;/Configuration&gt;In this setup, when you start the sandbox, it will automatically run the batch script firefox_download.bat from the shared folder, which downloads and installs Firefox. After installation, Firefox should start automatically.Remember to adjust the paths and script names according to your setup."
  },
  
  {
    "title": "Uptime Kuma Website monitoring tool",
    "url": "/posts/Uptime-Kuma/",
    "categories": "docker",
    "tags": "docs, windows, linux, docker, self-hosting",
    "date": "2024-01-17 23:00:00 -0800",
    





    
    "snippet": "A fancy self-hosted monitoring toolUptime Kuma is a self-hosted monitoring tool that allows you to keep track of the uptime and downtime of various internet services and websites. It‚Äôs essentially ...",
    "content": "A fancy self-hosted monitoring toolUptime Kuma is a self-hosted monitoring tool that allows you to keep track of the uptime and downtime of various internet services and websites. It‚Äôs essentially a personal status page and monitoring server. Here are some key features and benefits:      Self-Hosted and Open Source: Uptime Kuma is completely open-source and can be self-hosted, which means you have full control over the monitoring process and data. This is particularly beneficial for those who prefer to manage their monitoring systems within their own infrastructure for privacy and customization reasons.        Multiple Monitoring Types: It supports various types of monitoring methods, such as HTTP(s), TCP, HTTP(s) Keyword, Ping, DNS Record, and more. This flexibility allows you to monitor a wide range of services effectively.        Alerts and Notifications: Uptime Kuma provides real-time notifications when a monitored service goes down or becomes unreachable. You can receive these alerts through various channels like Telegram, email, webhook, and more, enabling quick response to issues.        Dashboard and Statistics: It offers a user-friendly dashboard that displays the status of all monitored services. You can see uptime percentages, response times, and other critical metrics, which can help in analyzing the performance and reliability of your services.        Customizable and Extendable: Since it‚Äôs open source, you can customize and extend its functionalities according to your specific monitoring needs.  Uptime Kuma is a versatile and user-friendly tool that helps in proactive monitoring of web services, ensuring you‚Äôre immediately alerted to any downtime or performance issues, which is crucial for maintaining a good user experience and service reliability.‚≠ê Features  Monitoring uptime for HTTP(s) / TCP / HTTP(s) Keyword / HTTP(s) Json Query / Ping / DNS Record / Push / Steam Game Server / Docker Containers  Fancy, Reactive, Fast UI/UX  Notifications via Telegram, Discord, Gotify, Slack, Pushover, Email (SMTP), and 90+ notification services, click here for the full list  20-second intervals  Multi Languages  Multiple status pages  Map status pages to specific domains  Ping chart  Certificate info  Proxy support  2FA supportüîß How to Installüê≥ Dockerdocker run -d --restart=always -p 3001:3001 -v uptime-kuma:/app/data --name uptime-kuma louislam/uptime-kuma:latestUptime Kuma is now running on http://localhost:3001WARNING  File Systems like NFS (Network File System) are NOT supported. - Please map to a local directory or volume.You can also install a watchtower docker container on the same host to always keep uptime kuma up to date by runningdocker pull containrrr/watchtower:latestOther Install methodshttps://github.com/louislam/uptime-kuma"
  },
  
  {
    "title": "BTC Mempool AI on GPT Store",
    "url": "/posts/BTC-Mempool-AI/",
    "categories": "ai",
    "tags": "ai, gpt, openai, bitcoin",
    "date": "2024-01-17 23:00:00 -0800",
    





    
    "snippet": "BTC Mempool AiReal-time data from the bitcoin mempool. Check your addresses, transactions, UTXO‚Äôs . Get current mempool fee rates and a lot more!Open AI BTC MemPoolhttps://chat.openai.com/g/g-fhvMW...",
    "content": "BTC Mempool AiReal-time data from the bitcoin mempool. Check your addresses, transactions, UTXO‚Äôs . Get current mempool fee rates and a lot more!Open AI BTC MemPoolhttps://chat.openai.com/g/g-fhvMWr0qz-btc-mempool-aiFeatures  Bitcoin Price Information          Get the latest Bitcoin price in various currencies.        Transaction Details          Retrieve detailed information about specific Bitcoin transactions.        Bitcoin Address Data          Analyze transactions associated with a given Bitcoin address.      Validate Bitcoin addresses.        Unspent Transaction Outputs (UTXOs)          Fetch UTXO data for a specific Bitcoin address.        Blockchain Insights          Get details about specific blocks in the blockchain.      Find blocks by timestamp.      Access block height and hash details.        Mempool Data          Provide insights into the current state of the mempool, including transactions count, total fee, and more.      Analyze mempool block fees.        Mining Information          Retrieve current and historical hashrate data.      Analyze difficulty adjustments in the Bitcoin network.        Fee Recommendations          Suggest fees for different confirmation time expectations.        Transaction Broadcasting          Broadcast raw transactions in hex format (upon user request).        Educational Content          Offer expert explanations and tutorials related to Bitcoin and its blockchain.      Note: All data and insights are retrieved and interpreted using integrated OpenAPI specifications for up-to-date and accurate information.Update 6/28/24I have built a full standalone app using chainlit you can find it herehttps://github.com/bigsk1/btc-mempool-ai"
  },
  
  {
    "title": "Employ Business Rankings",
    "url": "/posts/Employ-business-ranking/",
    "categories": "python",
    "tags": "python, flask, docs",
    "date": "2024-01-15 09:00:00 -0800",
    





    
    "snippet": "Employ Business Ratings AppGet an overall ranking score for a business from various resources in one place.I started building this app because I wanted to be able to rank a business on many factors...",
    "content": "Employ Business Ratings AppGet an overall ranking score for a business from various resources in one place.I started building this app because I wanted to be able to rank a business on many factors, say I am an employee looking for a job and trying to figure out what businesses I might like to work for. It is a good start and covers a few basic variables. Google, BBB and Yelp, as well as the company‚Äôs turnover rate of employees, the credit score if known. You can assign weights to these factors to determine how much you care about it in the final ranking.So it is a start I would like to add more variables like business awards, other related rating api‚Äôs. You will need to get Google api, Yelp Api and BBB token.Fell free if you have any interest to help build it add a pull request.OverviewThe Employ Rating System is a web and cli application designed to calculate and display the overall rating of businesses based on various data points. The application fetches ratings from multiple sources like Yelp, Google Places, and BBB, and calculates a weighted average to provide an overall score for a business.Features  User Interface: A web-based UI that allows users to input business details and view the calculated ratings.  Configurable Weights: Users can configure the weightage given to each rating source.  Log Management: The application logs all the rating details and API responses for debugging and transparency.  Data Persistence: Uses YAML files to store configuration settings.  Downloadable Logs: Users can download the log files for offline analysis.InstallationWinodws or LinuxPrerequisites  Python 3.x  Docker (optional)  Conda (optional for environment management)Local SetupUsing Python‚Äôs built-in venv  Clone the repositorygit clone https://github.com/bigsk1/employ.git  Navigate to the project directorycd employ  Create a virtual environmentpython -m venv .venv  Activate the virtual environment          On Windows:      .venv\\Scripts\\activate  On macOS and Linux:source .venv/bin/activate  Install required packagespip install -r requirements.txt  Run the applicationpython app.pyYou can also run from CLI python main.py and get output in terminalUsing Conda  Install Conda if you haven‚Äôt already.      Create a new Conda environment     conda create -n employ python=3.11.0            Activate the Conda environment     conda activate employ        Follow steps 1, 2, 5, and 6 from the ‚ÄúUsing Python‚Äôs built-in venv‚Äù section.Docker  Docker imagedocker pull bigsk1/employ:latest  Use the provided docker-compose.yml file to start the container.docker-compose upOR  Use a docker run command instead, add additional -e as neededdocker run --restart=always -p 5000:5000 -e YELP_API_KEY=yourkey bigsk1/employ:latestvisit localhost:5000Usage  Open your web browser and navigate to http://localhost:5000.  Input the business details and configure the weights for each rating source.  Click the ‚ÄúRun‚Äù button to fetch the ratings and calculate the overall score.Environment VariablesThe application uses the following environment variables for API access:  YELP_API_KEY  GOOGLE_API_KEY  BBB_API_TOKENThese can be set in a .env file in the project directory.You need to sign up and get the API keys and tokens to use the those optionsFuture Additions  Integration of more APIs to enhance the business ranking system.  Incorporation of awards or recognitions that could positively influence a business‚Äôs score.  Adapt the tool for job seekers to evaluate potential employers.  Add manual entry fields for other factors important in business evaluation.  Implement industry-specific ranking systems with different weights or criteria.Githubhttps://github.com/bigsk1/employ"
  },
  
  {
    "title": "TermSite - Static Terminal profile site",
    "url": "/posts/TermSIte/",
    "categories": "vercel",
    "tags": "vercel, node, typescript, docs",
    "date": "2024-01-13 09:00:00 -0800",
    





    
    "snippet": "üíª TermSite - build a terminal styled websiteHighly customizable, easy-to-use, and minimal terminal styled website template, powered by Next.js.Building a simple website with TermSite and you only n...",
    "content": "üíª TermSite - build a terminal styled websiteHighly customizable, easy-to-use, and minimal terminal styled website template, powered by Next.js.Building a simple website with TermSite and you only need to work with the file: config.json.https://bigsk1.vercel.app/Docker UsageFirst, clone the project and edit config.json to your liking. Then run the following to start the container in DEV mode uses (port 3005)docker-compose up -d --build termsiteTo run docker container in production mode uses (port 3000)docker-compose up -d --build termsite-prodüìÑ Basic Configuration90% of TermSite‚Äôs configurations are done through the config.json file.{  \"readmeUrl\": // create a Github README and link it here!  \"title\": // title of the website  \"name\": // your name, included in 'about' command  \"ascii\": // ascii art to display  \"social\": {    \"github\": // your handle    \"linkedin\": // your handle  },  \"email\": // your email  \"ps1_hostname\": \"liveterm\" // hostname in prompt  \"ps1_username\": \"visitor\", // username in prompt  \"resume_url\": \"../resume.pdf\", // path to your resume  \"non_terminal_url\": \"W\",  \"colors\": {    \"light\": {      ...    },    \"dark\": {      ... // you can use existing templates in themes.json or use your own!    }  }}Feel free to change it as you see fit!ThemesYou can find several pre-configured themes in themes.json, and you can replace the colors in config.json with the theme color you like! The themes are based on the themes on this website.For a better preview of the themes, checkout the images in the demo folder.FaviconsFavicons are located in public/, along with the other files you may want to upload to your website. I used this website to generate favicons.BannerYou may also want to change the output of the banner command. To do that, simply paste your generated banner in src/utils/bin/commands.ts. I used this website to generate my banner.Advanced ConfigurationIf you want to further customize your page, feel free to change the source code to your liking!üåê Deploy on VercelThe easiest way to deploy a Next.js app is to use the Vercel Platform from the creators of Next.js.You can install vercel cli and follow the instruction here.You can also connect your github account to vercel and have vercel automatically deploy the github repository for you.Githubhttps://github.com/bigsk1/TermSiteCreditBased on M4TT72‚Äôs awesome Terminal.Made from Fork at https://github.com/Cveinnt/LiveTerm"
  },
  
  {
    "title": "Send a Message in Bitcoin Transactions",
    "url": "/posts/Bitcoinlib-RPC/",
    "categories": "bitcoin",
    "tags": "bitcoin, python, linux",
    "date": "2024-01-13 09:00:00 -0800",
    





    
    "snippet": "Bitcoinlib RPC ProjectSo I wanted to see if I could add a message in a bitcoin transaction and have it permanently on the blockchain. The recent hack with the SEC‚Äôs twitter account and post of the ...",
    "content": "Bitcoinlib RPC ProjectSo I wanted to see if I could add a message in a bitcoin transaction and have it permanently on the blockchain. The recent hack with the SEC‚Äôs twitter account and post of the bitcoin Spot ETF was kinda funny considering the SEC didn‚Äôt secure there account with 2fa and they had a post recently about security and recommending just that using 2fa online.https://twitter.com/SECGov/status/1744837121406349714So I went about trying to do this with no experiance adding a message in a bitcoin transaction. I‚Äôm sure there are tools or wallets out there that would make this process easy, but I wondered if I could do this in python and also use my own bitcoin node. Also building something new can be fun.Searching for python options I found bitcoinlib on github a library for creating and managing bitcoin wallets with quite a few stars and contributors. I was pretty straight forward to make a wallet and get the first public key address and private key, which I made a script shown in the instructions below.Once I sent a few sats to the public address and checked on the block explorer I was ready to create a transaction, sign it, add a message using the OP_RETURN method and send it to another address I own.I was able to add the RPC local network connection to use my own node ( umbrel OS ) but I‚Äôm sure citidel or raspiblitz or others would also work just need the RPC creds, I‚Äôm also sure you could use the RPC connection on a public clearnet ip if you have the correct https certs setup but that involves a deeper dive and modifying the script.Once the script ran succesfully I got a TXID along with the Raw Hex code and instantly (cause my vsat was high enough to get into the next block) got a notification on my other wallet so I knew it was a success.Copying the TXID and pasting it into the bitcoin block explorer you can see the details and the OP_RETURN message and in my case was the twitter url to the SEC post.What the scripts doAllows you to use your locally hosted Bitcoin node (like Umbrel) and bitcoinlib in Python to create a wallet and send OP_RETURN message in a Bitcoin transaction with small changes in the python files by adding your info.Used with Linux ( tested in WSL2 Ubuntu on one machine and umbrel bitcoin node on your local network like a Raspiberry Pi ) below is an example of a successful transaction.mempool block explorer btc transactionAnother bitcoin block explorer is opreturn.net which shows the op_return messages betterOpReturn block explorer btc transactionOverview  Create a new wallet and generate a text file with wallet name, public address, and private key.  Modify Python files to add your details.  Run a curl command to test RPC connection to your node.  Send a small amount of funds to your new wallet to cover the outgoing transaction and fees.  Run a script to get updated info about your wallet.  Run a script to send a transaction with your message.  Check the block explorer with the TXID to see your message.Installation and Setup  Install Python 3.10 (3.11 might work but is untested). You can create a conda environment with Python 3.10.4.  Install bitcoinlib: pip install bitcoinlib  Install required dependencies: sudo apt install build-essential python3-dev libgmp3-devCreate Wallet  Open create_test_wallet.py and change the wallet name at the bottom (avoid spaces).  Run python create_test_wallet.py  You will get a .txt file with wallet details, including the private key in WIF format.Set Environment VariablesAdded your details and run the following to your terminal or you can add the secrets to your .bashrcIf using umbrel or similar select bitcoin node, connect, RPC local network credintialsexport BITCOIN_NODE_HOST='your_node_ip'export BITCOIN_NODE_PORT='your_node_port'export BITCOIN_RPC_USERNAME='your_rpc_username'export BITCOIN_RPC_PASSWORD='your_rpc_password'export MY_BTC_PRIVATE_KEY='your_private_key_here'Configure Bitcoin RPC Connection in bitcoinlib  Edit ~/.bitcoinlib/bitcoin.conf and add your details:[rpc]rpcconnect=192.168.x.xxrpcport=8332rpcuser=umbrelrpcpassword=XXXXXXXXXXXXXXXXXXXXXXXXXXtxindex=1server=1Test RPC Connection  Run the following curl command to check if the RPC connection is working (fill in your username, password, IP, and port):curl --user rpc_user_name:rpc_password --data-binary '{\"jsonrpc\": \"1.0\", \"id\":\"curltest\", \"method\": \"getblockchaininfo\", \"params\": [] }' -H 'content-type: text/plain;' http://ip:port/Fund Your Wallet  Send funds to your new wallet‚Äôs public address (from the .txt file). Make sure to send enough to cover the amount you send out of the wallet + mining fees, you can check current mempool fees before sending at https://mempool.space/  Wait for confirmations on a block explorer or run python wallet_scan_details.py (enter the correct wallet name inside file).Prepare and Send Transaction  Open btcmessage_rpc.py , look under Configuration code block  Add your wallet name, public address, sender‚Äôs address, fee, sending amounts, and your message (less than 80 bytes). Note the amount to send and fees are in btc like (0.001), so use a calculator to convert BTC to USD,  https://coinmarketcap.com/converter/btc/usd  Run the script to send your transaction when ready.Run python btcmessage_rpc.py  This script uses the wallet you created in bitcoinlib, gets it up to date with UTXOs, creates the transaction, extracts the raw transaction hex, and then sends it to your Bitcoin node for broadcasting. If successful, you will see the TXID and the raw transaction hex.Copy your TXID and paste it in a block explorer like Mempool https://mempool.space/ to see your OP_RETURN message and details.Github RepoGithub repo: https://github.com/bigsk1/bitcoinlib_rpc"
  },
  
  {
    "title": "Sig Script - Signature on Images",
    "url": "/posts/Sig-Script/",
    "categories": "python",
    "tags": "docs, python, windows",
    "date": "2023-12-10 09:00:00 -0800",
    





    
    "snippet": "SigScriptThis script automatically adds a signature to all the Stable Diffusion images you generate or any image you want. The idea is to make it easier to brand your images with your own name or a...",
    "content": "SigScriptThis script automatically adds a signature to all the Stable Diffusion images you generate or any image you want. The idea is to make it easier to brand your images with your own name or alias. You can add a signature to hundreds of thousands of images quickly.üé• Demoüì∫ Watch Videoüìå Prerequisites  Python 3.10+  Windows 10/11üöÄ Quick StartInstall Python Virtual EnvironmentRun start.bat to install a Python virtual environment (venv).Edit the ScriptOpen the scripts/signature.py file in a text editor like Notepad.Set Image Folder PathChange the following line to point to your images folder.directory = r'C:\\add-your-image-folder-path-here'For example:directory = r'C:\\\\Users\\\\somedude\\\\Downloads'Add Your SignatureAdd your name or alias to the following line:signature_text = 'ADD YOUR NAME HERE'For example:signature_text = '-bigsk1'Customize AppearanceThe default font color is white, but you can change it by modifying the RGB values in the script. You can also change the font, line width, and size.Run the ScriptDouble-click start.bat to run the script.OutputThe signed images will be saved in the outputs folder. Original images will not be modified.File NamingIf your original image name is 00925-3431573143.png, the signed image will be saved as 00925-3431573143_signed.png.Supported File Types  .png  .jpg  .jpeg  .bmp  .tiff  Note: The script supports both upper and lowercase file extensions like `.PNG`.## Github repohttps://github.com/bigsk1/SigScript"
  },
  
  {
    "title": "Python Cheat Sheet",
    "url": "/posts/python-cheat-sheet/",
    "categories": "python",
    "tags": "python",
    "date": "2023-10-30 10:00:00 -0700",
    





    
    "snippet": "PYTHON 3.6+  CHEAT SHEETSample code for quick referenceString Operations# String concatenationfull_name = \"John\" + \" \" + \"Doe\"# String formattingformatted = f\"Hello, {full_name}\"# String methodslow...",
    "content": "PYTHON 3.6+  CHEAT SHEETSample code for quick referenceString Operations# String concatenationfull_name = \"John\" + \" \" + \"Doe\"# String formattingformatted = f\"Hello, {full_name}\"# String methodslowercase = full_name.lower()uppercase = full_name.upper()split_name = full_name.split(\" \")# String slicingsubstring = full_name[1:4]List [ ]Mutability: Mutable - CAN CHANGEDescription: Ordered sequence of elements.Common Uses: Storing collections of items, iteration, sorting, etc.Notes: Supports indexing and slicing. Elements can be added, modified, or removed.# Examplemy_list = [1, 2, 3]my_list.append(4)  # Adds 4 to the end of the list# Creating listsmy_list = [1, 2, 3]# Appending to listmy_list.append(4)# Extending listmy_list.extend([5, 6, 7])# Slicing listfirst_two = my_list[:2]# Removing itemsmy_list.remove(1)Tuple ( )Mutability: Immutable - CAN NOT CHANGEDescription: Ordered sequence of elements.Common Uses: Storing collections of items that should not be modified.Notes: Similar to lists but cannot be altered once defined. Useful for hashable keys in dictionaries.# Examplemy_tuple = (1, 2, 3)Set { }Mutability: Mutable - CAN CHANGEDescription: Unordered collection of unique elements.Common Uses: Removing duplicates, set operations like union and intersection.Notes: Items in a set are unique. Adding an existing item has no effect. Sets themselves are mutable, but the elements inside them must be immutable (e.g., numbers, strings, tuples).# Examplemy_set = {1, 2, 3}my_set.add(4)  # Adds 4 to the setmy_set.add(1)  # No change, since 1 is already in the setDictionary {key: value}Mutability: Mutable - CAN CHANGEDescription: Unordered collection of key-value pairs.Common Uses: Associative arrays, hash tables.Notes: Keys must be immutable (e.g., numbers, strings, tuples), but values can be mutable objects.# Examplemy_dict = {'a': 1, 'b': 2}my_dict['c'] = 3  # Adds a new key-value pair# Creating dictionarymy_dict = {'key': 'value'}# Accessing valuesvalue = my_dict['key']# Adding new key-value pairmy_dict['new_key'] = 'new_value'# Removing key-value pairdel my_dict['key']# Checking if key existsif 'key' in my_dict:    print(\"Key exists\")So to break it down for nested dictionary below:weights: This is a variable that holds a dictionary.‚Äòyelp‚Äô and ‚Äòturnover‚Äô: These are keys within the weights dictionary.config[‚Äòyelp‚Äô][‚Äòweight‚Äô] and config[‚Äòturnover‚Äô][‚Äòweight‚Äô]: These are values that are being retrieved from another dictionary (config) and stored as values in the weights dictionary.# Define a nested dictionary for configconfig = {    'yelp': {        'weight': 0.6    },    'turnover': {        'weight': 0.4    }}# Define a dictionary for weights that takes values from configweights = {    'yelp': config['yelp']['weight'],  # 0.6    'turnover': config['turnover']['weight']  # 0.4}If, Elif, Else# Basic if-elif-elsex = 10if x &gt; 5:    print(\"x is greater than 5\")elif x == 5:    print(\"x is 5\")else:    print(\"x is less than 5\")# Check if item is in a listnumbers = [1, 2, 3]if 2 in numbers:    print(\"2 is in the list\")# Check multiple conditionsif x &gt; 5 and x &lt; 15:    print(\"x is between 5 and 15\")While Loop# Basic while loopcount = 0while count &lt; 5:    print(count)    count += 1# While loop with breakcount = 0while True:    if count &gt;= 5:        break    print(count)    count += 1For Loop# Basic for loopfor i in range(5):    print(i)# For loop with listfor num in [0, 1, 2, 3, 4]:    print(num)Try and Except# Basic try-excepttry:    x = 1 / 0except ZeroDivisionError:    print(\"Cannot divide by zero\")# Multiple exceptionstry:    # code that may raise an exception    x = 1 / 0except (ZeroDivisionError, ValueError):    print(\"An error occurred\")# Catch exception and get error messagetry:    # code    x = 1 / 0except Exception as e:    print(f\"An error occurred: {e}\")Functions# Basic functiondef greet(name):    return f\"Hello, {name}\"# Function with default argumentdef greet(name=\"World\"):    return f\"Hello, {name}\"# Function with arbitrary number of argumentsdef sum_all(*args):    return sum(args)# Function with keyword argumentsdef greet_with_log(name, log=False):    if log:        print(f\"Logging: Greeted {name}\")    return f\"Hello, {name}\"File Operations# Reading a filewith open('file.txt', 'r') as f:    content = f.read()# Writing to a filewith open('file.txt', 'w') as f:    f.write('Hello, World!')# Appending to a filewith open('file.txt', 'a') as f:    f.write('\\nAppending text')Importing Modules and Libraries# Importing entire moduleimport math# Importing specific functionfrom math import sqrt# Importing and aliasingimport numpy as npWorking with Datesfrom datetime import datetime, timedelta# Get current date and timenow = datetime.now()# Format dateformatted_date = now.strftime('%Y-%m-%d %H:%M:%S')# Date arithmetictomorrow = now + timedelta(days=1)Basic Logging to Consoleimport logging# Basic logginglogging.basicConfig(level=logging.INFO)logging.info('This is an info message')Logging Levels# Available logging levels in increasing order of severitylogging.debug('Debug message')logging.info('Informational message')logging.warning('Warning message')logging.error('Error message')logging.critical('Critical error message')Logging to a File# Logging to a filelogging.basicConfig(filename='app.log', level=logging.INFO)logging.info('Logged to file')Advanced Logging: Handlers and Formattersimport logging# Create loggerlogger = logging.getLogger('my_logger')logger.setLevel(logging.INFO)# Create console handler and set level to debugconsole_handler = logging.StreamHandler()console_handler.setLevel(logging.DEBUG)# Create file handler and set level to infofile_handler = logging.FileHandler('app.log')file_handler.setLevel(logging.INFO)# Create formatterformatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')# Add formatter to handlersconsole_handler.setFormatter(formatter)file_handler.setFormatter(formatter)# Add handlers to loggerlogger.addHandler(console_handler)logger.addHandler(file_handler)# Log messageslogger.debug('Debug message')logger.info('Info message')logger.warning('Warning message')logger.error('Error message')logger.critical('Critical message')Exception Loggingtry:    x = 1 / 0except Exception as e:    logging.error(f'An error occurred: {e}', exc_info=True)Conditional Loggingx = 5if x &lt; 10:    logging.warning(f'x is less than 10: x={x}')Arithmetic Operatorsprint(3 + 2)     # Addition: 5print(3 - 2)     # Subtraction: 1print(3 * 2)     # Multiplication: 6print(3 / 2)     # Division: 1.5print(3 % 2)     # Modulus: 1print(3 ** 2)    # Exponentiation: 9print(3 // 2)    # Floor Division: 1Comparison Operatorsprint(3 == 2)    # Equal: Falseprint(3 != 2)    # Not equal: Trueprint(3 &gt; 2)     # Greater than: Trueprint(3 &lt; 2)     # Less than: Falseprint(3 &gt;= 2)    # Greater than or equal to: Trueprint(3 &lt;= 2)    # Less than or equal to: FalseLogical Operatorsprint(True and False)    # and: Falseprint(True or False)     # or: Trueprint(not True)          # not: FalseAssignment Operatorsa = 3a += 2        # Add and assign: a = 5a -= 1        # Subtract and assign: a = 4a *= 2        # Multiply and assign: a = 8a /= 4        # Divide and assign: a = 2.0Bitwise Operatorsprint(3 &amp; 2)    # Bitwise AND: 2 (0b11 &amp; 0b10 = 0b10)print(3 | 2)    # Bitwise OR: 3 (0b11 | 0b10 = 0b11)print(3 ^ 2)    # Bitwise XOR: 1 (0b11 ^ 0b10 = 0b01)print(~3)       # Bitwise NOT: -4 (two's complement of 0b11 is -0b100)print(3 &lt;&lt; 1)   # Bitwise left shift: 6 (0b11 &lt;&lt; 1 = 0b110)print(3 &gt;&gt; 1)   # Bitwise right shift: 1 (0b11 &gt;&gt; 1 = 0b1)Membership Operatorsnumbers = [1, 2, 3, 4, 5]print(3 in numbers)       # in: Trueprint(6 not in numbers)   # not in: TrueIdentity Operatorsa = [1, 2, 3]b = ac = [1, 2, 3]print(a is b)       # is: True (a and b refer to the same list)print(a is c)       # is: False (a and c are equal but refer to different lists)print(a is not c)   # is not: TrueWe can put it all together in a single Python script if needed.Example of all code togetherBelow is an example Python script that integrates various elements: variables, data types, functions, control structures (if, elif, else, while), error handling (try and except), and logging. This example aims to show how these elements can work together in a single Python script.import logging# Initialize logginglogging.basicConfig(level=logging.INFO)# Function Definitionsdef greet(name):    return f\"Hello, {name}!\"def is_even(number):    return number % 2 == 0def add(a, b):    return a + b# Logging examplelogging.info(\"Starting the program\")# Variablesname = \"Ivan\"age = 30# Listnumbers = [1, 2, 3, 4]# Dictionaryperson = {'name': 'Ivan', 'age': 30}# Basic if-elif-elseif age &gt;= 18:    logging.info(\"You are an adult.\")elif age &gt;= 13:    logging.info(\"You are a teenager.\")else:    logging.info(\"You are a child.\")# Using functionsgreeting = greet(name)logging.info(greeting)# Error handling with try-excepttry:    result = add(\"10\", 20)except TypeError as e:    logging.error(f\"An error occurred: {e}\")# Loop with whilecounter = 0while counter &lt; 3:    logging.info(f\"Counter is at {counter}\")    counter += 1# Check if a number is evenif is_even(10):    logging.info(\"The number is even.\")else:    logging.info(\"The number is odd.\")# Logging examplelogging.info(\"Ending the program\")"
  },
  
  {
    "title": "Autogen Agents",
    "url": "/posts/AutoGen-coding-agents/",
    "categories": "ai",
    "tags": "ai, docs, windows, linux",
    "date": "2023-10-15 10:00:00 -0700",
    





    
    "snippet": "AutogenIntroductionAutogen is an open-source project by Microsoft that aims to automate the generation of code, data, and documentation. It‚Äôs designed to streamline the development process by reduc...",
    "content": "AutogenIntroductionAutogen is an open-source project by Microsoft that aims to automate the generation of code, data, and documentation. It‚Äôs designed to streamline the development process by reducing the manual effort required to create and maintain these essential components.What is Autogen?Autogen is a tool that helps developers automate various aspects of software development. It can generate code, data, and documentation based on predefined templates and configurations. The project is hosted on GitHub and is open for contributions from the developer community.How Does Autogen Work?Autogen uses a combination of templates and configuration files to generate the required output. The templates define the structure and format of the code, data, or documentation, while the configuration files specify the variables and parameters to be used. When you run Autogen, it reads these files and produces the output accordingly.Installation GuideAutoGen requires Python version &gt;= 3.8. It can be installed from pip:pip install pyautogenMinimal dependencies are installed without extra options. You can install extra options based on the feature you need.Find more options in Installation.For code execution, we strongly recommend installing the python docker package, and using docker.For LLM inference configurations, check the FAQs.Why is Autogen Useful?  Efficiency: Autogen can significantly speed up the development process by automating repetitive tasks.  Consistency: It ensures that the generated code, data, and documentation follow a consistent structure and format.  Customization: You can customize the templates and configurations to suit your specific needs.  Collaboration: Being an open-source project, it encourages community contributions, allowing for continuous improvement.Future ProspectsAutogen has the potential to become an integral part of modern software development practices. With the growing complexity of projects and the increasing need for automation, tools like Autogen can play a crucial role in enhancing productivity and maintaining quality.ConclusionAutogen is a powerful tool that can automate various aspects of software development, making the process more efficient and consistent. With its customizable templates and configurations, it offers a flexible solution for developers looking to streamline their workflow.There are some promising projects that have been started using autogen.Agentsflowhttps://github.com/jaemil/agentsflowautogen ui/flow with:fastapiwebsocketsnextjsshadcn/uAutogen-UIExample of experimental UI for working with AutoGen agents, based on the AutoGen library. The UI is built using Next.js and web apis built using FastApi.https://github.com/victordibia/autogen-uiAutogen InteractiveCodinghttps://github.com/Andyinater/AutoGen_IterativeCodingAutogen dev studiohttps://github.com/ivangabriele/openai-autogen-dev-studioAgentsflowhttps://github.com/jaemil/agentsflowüì∫ Watch Video"
  },
  
  {
    "title": "MSI bios update bricks Windows 11 activation",
    "url": "/posts/MSI-bios-update-ruins-windows-activation/",
    "categories": "windows",
    "tags": "docs, msi, windows",
    "date": "2023-09-15 10:00:00 -0700",
    





    
    "snippet": "Windows 11 Activation Issues After MSI BIOS UpdateIntroductionMany users have reported issues with Windows 11 activation after updating their MSI BIOS and well as having your pin removed and having...",
    "content": "Windows 11 Activation Issues After MSI BIOS UpdateIntroductionMany users have reported issues with Windows 11 activation after updating their MSI BIOS and well as having your pin removed and having to remove and add your pin number for login again. This post aims to provide a comprehensive guide to discussing this issue. We‚Äôll cover the steps recommended by Microsoft, as well as alternative methods discussed in forums and YouTube videos.I did run the sfc /scannow option in windows and there were some files that were fixed so updating the bios caused issues within windows 11 OS. This issues seems to have been happening since 2022 and still no official fix. I am running a MSI Z790 ATX-E.Table of Contents  Windows 11 Activation Issues After MSI BIOS Update          Introduction      Table of Contents      Microsoft‚Äôs Official Solution                  Custom Installation via ISO File                    Alternative Methods                  Disabling TPM Before BIOS Update                    Community Insights      Conclusion      Microsoft‚Äôs Official SolutionI contacted microsoft and spoke with someone and the only thing they could offer is to reinstall windows and select keeping your folders and files intact. I have a highly customized and personalized version and the thought of weeks of customizations gone is not a fix.Custom Installation via ISO File  Download the ISO file of Windows 10 from the Media Creation Tool.  Launch the Media Creation Tool and click on ‚ÄúAccept‚Äù.  Choose ‚ÄúCreate Installation Media‚Äù.  Select ‚ÄúISO‚Äù and save it on your Desktop.  Open the ISO file and navigate to the Source folder.  Click on the ‚ÄúSetup file‚Äù.  A new window will open; click on ‚ÄúNext‚Äù.  Choose ‚ÄúCustom installation‚Äù.  Select the drive where you want to install Windows.  Click on ‚ÄúNext‚Äù.  Note: This process might take around half an hour. For a video guide, visit Microsoft‚Äôs official video.Alternative MethodsDisabling TPM Before BIOS Update  Go into the BIOS settings.  Disable the Firmware TPM option.  Save and reboot to Windows.  Perform the BIOS update.  Reboot and go back into the BIOS settings.  Re-enable the Firmware TPM option.  Note: This method is based on a YouTube video that suggests disabling TPM can help avoid deactivation issues.Community InsightsAccording to a forum discussion, users with a digital license face more challenges in reactivating Windows. Some suggest that entering a key, if available, might resolve the issue, but this is not guaranteed.ConclusionMicrosoft‚Äôs official solution of reinstalling windows is crap and the community-provided methods are not 100% provide to work. Hopefully you bought your microsoft account with a key that could be entered again and it works. I ended up just buying another windows 11 pro license and said the hell with it time is money but reinstalling windows and keeping your personal files might be the only option at this point. Unless you know about this issue ahead of time and doing the disable TPM in bios first trick then you might have to reinstall windows.Update 3/2024So after updating the bios again and having the samething happen, I dug deeper and found a solution. It was very simple, you can use Microsoft Activation Scripts from github, it activates your Windows 10/11. Reading comments on the microsoft help center the microsoft techs actually have used this to solve such issues. You can find it herehttps://github.com/massgravel/Microsoft-Activation-ScriptsInstall Method - TraditionalDownload the file from GitHub or BitbucketRight-click on the downloaded zip file and extractIn the extracted folder, find the folder named All-In-One-VersionRun the file named MAS_AIO.cmdSELECT 1You will see the activation options. Follow the on-screen instructions.That's all.This solved the issue."
  },
  
  {
    "title": "Stable Diffusion Automatic1111 ascii images",
    "url": "/posts/SD-ascii-images/",
    "categories": "ai",
    "tags": "docs, ai, images, automatic1111, python, sdxl, script, windows",
    "date": "2023-09-05 10:00:00 -0700",
    





    
    "snippet": "Unveiling the Magic of ASCII Art using Stable Diffusion Automatic1111IntroductionIn the realm of AI and image processing, the Stable Diffusion Auto1111 Web UI has already made a name for itself. Bu...",
    "content": "Unveiling the Magic of ASCII Art using Stable Diffusion Automatic1111IntroductionIn the realm of AI and image processing, the Stable Diffusion Auto1111 Web UI has already made a name for itself. But what if we told you that this powerful tool has a new trick up its sleeve? Introducing the ASCII Art Image Converter, a nifty add-on script that transforms your images into mesmerizing ASCII art. This blog post will walk you through what this script does, how to use it, and what Stable Diffusion Automatic1111 is all about.What is Stable Diffusion Automatic1111?Stable Diffusion Automatic1111 is a Web UI designed for running AI image models. It offers a user-friendly interface that allows you to manipulate and generate images using various AI algorithms. The platform is highly extensible, allowing developers to add custom scripts and functionalities. One such add-on is the ASCII Art Image Converter, which we‚Äôll delve into next.ASCII Art Image Converter: An OverviewThis script is a game-changer for ASCII art enthusiasts and AI aficionados alike. It seamlessly integrates with the Stable Diffusion Web UI and can be found in the IMG2IMG section. The script provides a user interface that lets you adjust various parameters like ASCII width, letter spacing, font size, and font type.Features:  ASCII Width: Customize the width of your ASCII art. Range: 50-200.  Letter Spacing: Control the spacing between ASCII characters. Range: 0-20.  Font Size: Choose the font size of your ASCII characters. Range: 8-48.  Font Type: Pick from a variety of fonts, including ‚ÄúArial,‚Äù ‚ÄúCourier New,‚Äù ‚ÄúTimes New Roman,‚Äù ‚ÄúComic Sans MS,‚Äù and ‚ÄúVerdana.‚Äù  Background Colors: Choose from up to 20 different background colors to make your ASCII art pop!Installation and UsageGetting started with the ASCII Art Image Converter is a breeze. Follow these steps:      Installation: Place the asciiImage.py script into the stable-diffusion-webui/scripts directory of your Stable Diffusion Web UI installation.        Usage:          Open the Stable Diffusion Web UI and navigate to the IMG2IMG section.      Locate the dropdown for selecting scripts at the bottom of the IMG2IMG section.      Choose ‚ÄúConvert to ASCII Art Image‚Äù to activate the script.      Save the image directly from the Web UI, as it won‚Äôt be saved in the outputs img2img folder.      A .txt file containing the ASCII art will be generated in the outputs/img2img-images/ascii folder. You can copy and paste the ASCII art from this .txt file.      ConclusionThe ASCII Art Image Converter for Stable Diffusion Automatic1111 Web UI is a fantastic addition to an already robust platform. It opens up a world of possibilities for creative expression, combining the charm of ASCII art with the power of AI.The script is open-source and free to use. For more standalone ASCII art converters compatible with Linux, Windows, Docker, and VSCode DevContainer, check out bigsk1‚Äôs GitHub page for airats.Happy ASCII art creating"
  },
  
  {
    "title": "Resize and convert images to base64 and webp",
    "url": "/posts/Resize-and-convert-Images-to-base64/",
    "categories": "python",
    "tags": "docs, ai, base64, images, webp, python, windows",
    "date": "2023-09-02 10:00:00 -0700",
    





    
    "snippet": "Convert  images to webp and base64Small python script to resize and convert images to webp and provide base64 data in a .txt fileOverviewThe Base64 Convert App is a Python script that automates the...",
    "content": "Convert  images to webp and base64Small python script to resize and convert images to webp and provide base64 data in a .txt fileOverviewThe Base64 Convert App is a Python script that automates the process of converting images to Base64 format and resizing them. It‚Äôs particularly useful for embedding images directly into Markdown files for Jekyll-based websites. The app also generates WebP versions of the images for better compression and quality.Features  Converts images in the images folder to Base64 format.  Saves the Base64 string to a .txt file with the same name as the image.  Resizes the image to 250x160 pixels.  Converts the resized image to WebP format.  Saves the WebP image with a _converted.webp suffix.How to Use  Setup: Place the convert.py script in the same directory as your images folder.  Batch File: Double-click the provided .bat file. This will set up a Python virtual environment, install required packages, and run the convert.py script.  Output: After running, you‚Äôll find a .txt file containing the Base64 string and a _converted.webp image in the images folder for each image processed.Requirements  Python 3.x  Pillow library (automatically installed by the .bat file)Notes  The .bat file will check if a virtual environment already exists. If it does, it will simply activate it and run the script.  Detailed logs will be displayed in the CMD window, including any errors.LinuxUse the convert.shgive it execute permissions (chmod +x convert.sh), and then you can run it with ./convert.shFind it here on github Base64"
  },
  
  {
    "title": "Converting Images to ASCII",
    "url": "/posts/Converting-images-to-ASCII/",
    "categories": "python",
    "tags": "docs, ascii, images, docker, linux, windows",
    "date": "2023-09-02 10:00:00 -0700",
    





    
    "snippet": "AIRATSASCII Image Convertor - How to installA simple Flask web app and command-line tool to generate ASCII art from an image URL or locally.Both Web and Command Line usageTurn any image locally or ...",
    "content": "AIRATSASCII Image Convertor - How to installA simple Flask web app and command-line tool to generate ASCII art from an image URL or locally.Both Web and Command Line usageTurn any image locally or remotely into ASCII characters.This project can be found on github here ascii art generatorInstallationDockerdocker pull bigsk1/airats:latestorBuild docker image in project root with DockerfileClone the repo thencd airatsdocker build -t &lt;your_image_name&gt; .docker run -d -p 5000:5000 &lt;your_image_name&gt;Linux  Clone the repogit clone https://github.com/bigsk1/airats.gitcd airats  (Optional) Create a virtual environment and activate it:python3 -m venv venvsource venv/bin/activate  Install the required Python packages:pip install -r requirements.txtUbuntu 22.04+If you don‚Äôt want the virtual environment just make sure you have installedsudo apt install python3 &amp;&amp; sudo apt install python3-pip &amp;&amp; sudo apt install python3-flask &amp;&amp; python3 -m pip install Pillow &amp;&amp; python3 -m pip install requests &amp;&amp; python3 -m pip install gunicornrun with python3 app.py in the airats folderpython3 app.pyOpen a web browser and visit http://localhost:5000 to access the app.Devcontainer VScodeOpen in devcontainer and run! Find on localhost:5000Windows 64bit installDownload .exe from releases here: https://github.com/bigsk1/airats/releases/tag/v1.0You will most likely get a warning when trying to launch because it is not a signed .exe this is normal.(optional)  build your own by cloning the win64 branch here:git clone --single-branch --branch win64 https://github.com/bigsk1/airats.gitsee the requirements.txt for what dependencies are neededUsageLinuxWeb Interface virtual environment in Python  Run the Flask app (optional):export FLASK_APP=app.pyflask run --host=0.0.0.0      Open a web browser and visit http://localhost:5000 to access the app.        Enter an image URL and width, then click ‚ÄúGenerate ASCII Art‚Äù to see the result.  Command LineRun any of the following commands from the airats directory:python3 Main.py  [-w WIDTH] [-ht HEIGHT]Image size can be changed as neededYou can also run an image you have locally using:python3 Main.py your_image.jpg -w 150 -ht 50orpython3 Main.py https://your-image-url.jpeg -w 150 -ht 50python3 Main.py images/rat.jpg -w 50 -ht 25Output image to a filepython3 Main.py images/rat.jpg -w 80 -o output.txtSupportsJPEG: .jpg, .jpegPNG: .pngGIF: .gifBMP: .bmpTIFF: .tif, .tiffICO: .icoWebP: .webp                                                     `,^.`:l!&lt;;,^'   .I,                    !-})}rcYCQLYzvt(]?[{;                   \"+&lt;+}}{ruYQQQ0QJvft?--`                  ir1_-)jrzvucccJZwQvnj?}(,                .-CZJf[}rcnuzLu/tjnzvrYYcYtl               .1QQCL0XcnrxuO#pCjf/(|fcpXYCx,               ]CLXcccXJYJJXzcrttt({[{|/vLQL/^              +JLcrrnvYLCL0QLJCzt)]?[}}-)COLJ}`            !XZQcjrvXYCQQOO0QJu(}]?{?]?+zO0Lc&gt;            `tL00XnjncvcczXXXvf/|{[])()[]zLCXX{           \"rYYJYznxnvczzvuuuj({}]??][)uJCXvct'           ,jXXYzcvnnvzXJJJYYzvf/|fnzYCQYYzuvn^           .~ncccunuvcXJJXXYJ0mOqZZ00QO0JzvuvvI            '?xrrjrzOZJvcvXQOdkhadmQLLLLCznxczI              ~jrjt{)vQcvvut){(c0ZOQLLQQCcnuXX,   ^l&gt;+]{){]_!,l[/)&lt;!!]ncu1__&lt;]tuXCLQOZQYcvXJu' \"+{jj|)fxuzQ0Qzxnx]!!i]cvurftuczCL0OOLJYXYJCt ^[n/;.    .^!]rCwqQz|?{}cJLOOZZmpwmmO0QCYYCCC~`-/[^          '!1uQZ0CQOZmpdppkkbkpmOLCLOZOt' ^_(]~!,^````^\"\"`\":~(Jdhao*#*o#MMMhZQC0mmLvj,    :~?}}}1)/nXzuvC0qdh#W8#abdpwmOLXXvYYvt-!I'      .^\":;l!!l!i+-{(/tjf}???-}{1?]1(/{?&lt;!:,'                              ..            LICENSEThis project is licensed under MIT License."
  },
  
  {
    "title": "Silly Tavern webui with oobabooga",
    "url": "/posts/Silly-Tavern-with-oobabooga/",
    "categories": "ai",
    "tags": "docs, ai, oobabooga, silly-tavern, chatbot, llm, windows",
    "date": "2023-08-30 10:00:00 -0700",
    





    
    "snippet": "Silly TavernWhat is it?  What does it do?  How to use it?What is SillyTavern?SillyTavern is a program you can put on your computer or even your Android phone. It‚Äôs like a special frontend interface...",
    "content": "Silly TavernWhat is it?  What does it do?  How to use it?What is SillyTavern?SillyTavern is a program you can put on your computer or even your Android phone. It‚Äôs like a special frontend interface where you can talk to computer-generated characters. You can even make your own characters or use ones that other people have made. You will also need a backend that processes the chat models that you load, a Nvidia GPU 2090 and above is recommended.How Does it Work?SillyTavern is like the ‚Äúface‚Äù of the operation, but it needs a ‚Äúbrain‚Äù to actually have conversations. That brain is another program that does all the thinking for the characters. There are different kinds of brains you can use, like OpenAI‚Äôs GPT, KoboldAI, and more. Here we will be refering to Oobabooga Webui as you can run this on your local computer but there are many options.What‚Äôs Cool About It?  Mobile-Friendly: You can use it on your phone!  Multi-API: It can connect to different ‚Äúbrains‚Äù for the characters.  Waifu Mode: Imagine anime-style conversations!  System TTS: The characters can even ‚Äúspeak‚Äù to you.  WorldInfo: You can create backstories for your characters.  Customizable UI: Make it look the way you want.  Auto-Translate: It can speak different languages.  Prompt Options: You can set up how you want to start conversations.How to Get Started?Windows Users  Install NodeJS (it‚Äôs like the engine that runs the program).      Use GitHub Desktop to download SillyTavern or just make use you have installed git already        Open a folder where you want to put SillyTavern.    DO NOT INSTALL INTO ANY WINDOWS CONTROLLED FOLDER (Program Files, System32, etc).    DO NOT RUN START.BAT WITH ADMIN PERMISSIONS    Open Command Prompt in that folder and type some commands to set it up. In the file explorer bar type cmd and command prompt will open from that folder, then type    git clone https://github.com/SillyTavern/SillyTavern.git        cd into SillyTavern    Double-click Start.bat and it will open in your browser.SillyTavern has a detailed write up here SillyTavern install on windowsLinux Users  Just run the start.sh script.Can I Use it On My Phone?Yes, you can! There‚Äôs a guide for that, and you can use a program called Termux to make it work on Android.In-Depth Guide: SillyTavern with Oobabooga‚Äôs Web UI and Custom Chat ModelsPrerequisites  NodeJS: Make sure you have NodeJS installed on your system.It can be installed here node.js for windows  Git: You‚Äôll need Git to clone the SillyTavern repository. You can downloaded it here git_for_windows_and_linux  Oobabooga‚Äôs Web UI: This is the interface for your custom chat models. Make sure you have it set up and running. oobaooga install  Custom Chat Models: These are the censored and uncensored models you‚Äôll want to use for roleplay. Make sure they are compatible with Oobabooga‚Äôs Web UI.A few that I recommend areTheBloke/MythoMax-L2-13B-GPTQTheBloke/llama2_7b_chat_uncensored-GPTQTheBloke/Pygmalion-13B-SuperHOT-8K-GPTQTheBloke/airoboros-l2-13b-gpt4-m2.0-GPTQSteps for Windows 10/11 install1. Clone SillyTavern RepositoryOpen your terminal and run:git clone https://github.com/SillyTavern/SillyTavern -b release2. Navigate to the SillyTavern Directorycd SillyTavern3. Install DependenciesRun the following command to install the required NodeJS packages:npm install4. Start SillyTavernRun the following command to start SillyTavern:npm start5. Configure Oobabooga‚Äôs Web UI API ConnectionStart Oobabooga webui server first - see here for installing it Oobabooga Web Ui InstallIn SillyTavern, navigate to the settings and look for the API connections section. Here, you‚Äôll need to enter the details for connecting to Oobabooga‚Äôs Web UI. This usually involves specifying the API endpoint normally on http://127.0.0.1:78606. Load Custom Chat ModelsIn Oobabooga‚Äôs Web UI, make sure you load your chat models. These models should be accessible via the API you just connected to. In the Oobabooga folder look for webui.py and find the CMD_FLAGS and add the line so it looks like thisCMD_FLAGS = '--api'7. Test the ConnectionBack in SillyTavern, try initiating a chat to see if it uses your custom model from Oobabooga‚Äôs Web UI. If everything is set up correctly, your custom model should respond.8. Roleplay SetupYou can now set up your roleplay scenarios, characters, and other settings within SillyTavern. Given that you‚Äôre using a custom model, you should be able to roleplay without any content restrictions if using an uncensored model. You can also find charactor cards and download images and meta data here at chub.aiTroubleshooting  If you encounter issues, check the API logs in both SillyTavern and Oobabooga‚Äôs Web UI.  Make sure your custom models are loaded and accessible in Oobabooga‚Äôs Web UI.  Ensure that you‚Äôve correctly entered any required API tokens or authentication details ( if you set a username and password by default this is off ).The Extras ServerSillyTavern has an extras option which you download separately. You can check it out here SillyTavern ExtrasThe extras server you will want to run in a python environment - you will need python 3.11 as of 8/30/23Create a new virtual environment in the SillyTavern Home folder named ‚Äòvenv‚Äôpython3 -m venv venvthenvenv\\Scripts\\activateyou will see the (venv) now in terminalthen clone the extras repogit clone https://github.com/SillyTavern/SillyTavern-extras.gitif your using conda for the python environment then you will already know what to do and this is the best option because you can specify the python version.conda create -n sillyextras python=3.11.4and then conda activate sillyextrasOnce you are in your python environment and have cloned the extras repo then, cd SillyTavern-extras ,to get all the extra options use (recommend)pip install -r requirements-complete.txtOpen the file called config.conf in a text editor. The file is located in ST‚Äôs base install folder.Look for the line that reads const enableExtensions.Make sure that line has = true, and not = falseto run the extras server it would look like this, just pick the extras you would like to useExample: python server.py ‚Äìenable-modules=caption,summarize,classifyThis would enable Image Captioning, Chat Summary, and live updating Character ExpressionsOne click Installer on windows for running everything at onceI got tired of having to go and start every server manually when using SillyTavernI created a one click installer make a shortcut from it and place on your desktopIn the SillyTavern Home Directory make a .bat file and modify the path locations and services to fit your needs, this is placed in the sillytavern home directory and once made just right click it and make a shortcut from it and place on your desktop. My installer is using conda for my python environmentThis is my working Silly_Tavern_and_Extras.bat file as an example@echo offecho Starting oogabooga web UI...start cmd /k \"X:\\oobabooga\\oobabooga_windows\\start_windows.bat\"timeout /t 5echo Starting Stable Diffusion Automatic1111 web UI...cd X:\\SD\\stable-diffusion-webuistart cmd /k \"webui-user.bat\"timeout /t 30echo Starting SillyTavern server...pushd %~dp0start powershell -Command \"npm install --no-audit; node server.js\"timeout /t 10echo Starting SillyTavern Extras server...cd X:\\SillyTavern\\SillyTavern-extrasstart cmd /k \"call C:\\Users\\dude\\miniconda3\\Scripts\\activate.bat &amp;&amp; conda activate sillyextras &amp;&amp; python server.py --enable-modules=caption,chromadb,summarize,classify,sd --sd-remote-port 7861\"timeout /t 10echo Starting Silero API server...cd X:\\SillyTavern\\SillyTavern-extras\\silero-api-serverstart cmd /k \"call C:\\Users\\dude\\miniconda3\\Scripts\\activate.bat &amp;&amp; conda activate sillyextras &amp;&amp; python -m silero_api_server\"exitmake sure python and conda are added to path already and in windows you might have to allow execution policy by using this in admin powershellSet-ExecutionPolicy RemoteSigned -Scope CurrentUserIf you don‚Äôt want the .bat file in SillyTavern home folder, which I just make a shortcut once it‚Äôs there as that is easy and then put on desktop, you could modify, replace your path location as needed.pushd %~dp0start powershell -Command ‚Äúnpm install ‚Äìno-audit; node server.js‚Äùtocd X:\\SillyTavernstart powershell -Command ‚Äúnpm install ‚Äìno-audit; node server.js‚ÄùThis .bat file is used for all my self hosted services to startup one right after another  oobabooga  stable diffusion for image creation  Silly Tavern  Silly Tavern Extras - with all the flags enabled for services  Silero TTS for voicesJust modify the paths and services as needed for your use casealso shown here bigsk1 silly-tavern-gist"
  },
  
  {
    "title": "oobabooga Webui for chat models",
    "url": "/posts/Oobabooga-webui-for-chat-models/",
    "categories": "ai",
    "tags": "docs, ai, oobabooga, chatbot, llm, windows",
    "date": "2023-08-09 10:00:00 -0700",
    





    
    "snippet": "Gradio Web UI for Text GenerationWhat Is It?Easy VersionImagine you have a super-smart robot that can write stories, answer questions, or even chat like a human. This Gradio Web UI is like a remote...",
    "content": "Gradio Web UI for Text GenerationWhat Is It?Easy VersionImagine you have a super-smart robot that can write stories, answer questions, or even chat like a human. This Gradio Web UI is like a remote control for that robot. It‚Äôs a website where you can tell the robot what to do and see what it writes back.Why Use It?  Easy to Use: It‚Äôs like playing a video game! You don‚Äôt need to know how to code to use it.  Multiple Modes: You can use it like a notebook for school, like a chatbox, or even in a default mode that‚Äôs super simple.  Many Smart Robots: You can switch between different types of smart robots (called models) to see which one you like best.  Cool Features: You can do things like load different settings on-the-fly, or even train a new setting yourself!How to Use It?Step 1: Install ItEasy Way  Download a ZIP file for your computer (Windows, Linux, macOS, or WSL).  Unzip it and click on ‚Äústart.‚ÄùFor Tech-Savvy Kids  Use something called ‚ÄúConda‚Äù to install it manually. This is a bit complicated but gives you more control.Step 2: Start It  Open your computer‚Äôs command line.  Type some commands to go to the folder where you installed it.  Type python server.py and press Enter.Step 3: Use It  Open your web browser and go to http://localhost:7860/?__theme=dark.  Now you can start using it! Choose a smart robot, type something, and see what it writes back.Extra Tips  You can download more smart robots from a website called ‚ÄúHugging Face.‚Äù  If you want to update it later, you just need to run some simple commands.The Technical DetailsThe project is a Gradio web UI designed for text generation using large language models. It aims to be a comprehensive tool similar to AUTOMATIC1111‚Äôs stable-diffusion-webui. The UI supports various features:Interface Modes  Default mode  Notebook  ChatModel Support  Multiple backends like transformers, llama.cpp, ExLlama, AutoGPTQ, and more. Models can be downloaded on huggingface.Additional Features  Dropdown for model selection  On-the-fly LoRA loading and training  Precise instruction templates for chat mode  Support for 4-bit, 8-bit, and CPU inference  Efficient text streaming  Markdown and LaTeX outputInstallation  One-click installers for Windows, Linux, macOS, and WSL.  Manual installation using Conda is also available.Model Download  Models can be downloaded from Hugging Face and placed in a specific folder.Starting the Web UI  Activate the Conda environment and run the server script.The project is well-documented and offers various customization options, including settings for multi-user mode, model loader, and hardware acceleration.GitHub RepositoryGitHub LinkFor more details, users can refer to the project‚Äôs documentationWatch a YouTube VideoWatch a YouTube video on how to install oobabooga web UI here youtube install instructions"
  },
  
  {
    "title": "How to Install Stable Diffusion for Windows 10/11",
    "url": "/posts/Using-Stable-Diffusion-Automatic-1111/",
    "categories": "ai",
    "tags": "docs, ai, stable-diffusion, art, images, windows",
    "date": "2023-07-09 10:00:00 -0700",
    





    
    "snippet": "Using Stable Diffusion on your own PC HardwareAutomatic 1111 stable Diffusion webui is a great way to get started and run it on your own hardware. You should have a decent GPU, AMD or better yet a ...",
    "content": "Using Stable Diffusion on your own PC HardwareAutomatic 1111 stable Diffusion webui is a great way to get started and run it on your own hardware. You should have a decent GPU, AMD or better yet a Nividia RTX 2080 or newer.You can find the github repo here Stable Diffusion Github      Prepare Your Computer: Before you begin, your computer needs to have the right tools. You‚Äôll need to install Python Python 3.10 ( if you don‚Äôt have it already ) , which is like the language your computer needs to speak to run this program. You also need something called git, which is a way for your computer to talk to GitHub, where the program lives.        For Python, you need version 3.10.6. Even if there are newer versions, you need to stick with this one because the program we‚Äôre running needs it. Make sure to check the box that says ‚ÄúAdd Python to PATH‚Äù during installation. This lets your computer know where to find Python when it needs it.        Get the Program: Now that your computer has the tools, we can go get the program. We‚Äôre going to use git to download (or ‚Äúclone‚Äù) the program from GitHub. If you don‚Äôt have git you can get it here Install Git here  Open the command prompt (you can search for ‚Äòcmd‚Äô in your start menu), then type in  git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git and press Enter. This tells git to go to that website (github) and download the program. You can also create a new Folder anywere on your hard drive and in the file explorer address click in it and type cmd, it will open command prompt right to that path and then you can do the git clone.  Install the Program: After you‚Äôve downloaded the program, you‚Äôll have a new folder called ‚Äústable-diffusion-webui‚Äù on your computer. In this folder, you‚Äôll find a file called webui-user.bat. This is like the instruction manual for your computer. Double-click on this file to run it. You don‚Äôt need to run it as an administrator.Open your browser and type in the url box 127.0.0.1:7860 and your ready to start using Stable Diffusion.Run the Program: Now the program is all set up! Any time you want to run it, just go back to the ‚Äústable-diffusion-webui‚Äù folder and double-click webui-user.bat. You can also make a shortcut on your desktop to this file.A few notes about running the webui-user.batYou can add different options when starting stable diffusion, as you learn there can be additional options to add when starting SD like ‚ÄìxformersBelow is an example of what I use@echo offset PYTHON=set GIT=set VENV_DIR=set COMMANDLINE_ARGS= --xformersgit pullcall webui.batThere are a few youtubers that cover stable diffusion content really good, I would check them out for detailshttps://www.youtube.com/@OlivioSarikashttps://www.youtube.com/@Aitrepreneurhttps://www.youtube.com/@sebastiankamphhttps://www.youtube.com/@mreflow"
  },
  
  {
    "title": "How a GPT Agent Can Improve Your Everyday Life",
    "url": "/posts/Using-GPT-Agent-to-improve-your-everyday-life/",
    "categories": "ai",
    "tags": "docs, chatgpt, ai, gptagent",
    "date": "2023-04-28 10:00:00 -0700",
    





    
    "snippet": "How a GPT Agent Can Improve Your Everyday LifeIf you‚Äôre looking to improve your productivity and efficiency, a GPT (Generative Pre-trained Transformer) agent can be a valuable tool. Here are a few ...",
    "content": "How a GPT Agent Can Improve Your Everyday LifeIf you‚Äôre looking to improve your productivity and efficiency, a GPT (Generative Pre-trained Transformer) agent can be a valuable tool. Here are a few ways that taking advantage of pre-trained models can benefit you.Take Advantage of Pre-Trained ModelsMany GPT agents come pre-trained on a large corpus of data. By taking advantage of pre-trained models, you can save time and resources on training your own model. Additionally, pre-trained models are often more accurate and reliable than custom models.Benefits of Pre-Trained Models  Save time and resources on training  More accurate and reliable compared to custom models  Can be fine-tuned to specific tasks  Can be used for a variety of applicationsUse Cases for GPT AgentsGPT agents can be incredibly useful in a variety of situations. Here are a few examples:      Content creation: A GPT agent can be used to generate content for blog posts, articles, or social media posts. It can also be used to summarize articles or generate headlines.        Customer service: A GPT agent can be used to generate responses to customer inquiries or to provide automated customer service.        Personal productivity: A GPT agent can be used to generate to-do lists, reminders, or schedule appointments.  How a GPT Agent Can Improve Your Everyday LifeAre you tired of repetitive tasks that take up valuable time in your day? Do you wish you had a personal assistant to help you navigate complex tasks? Look no further than a GPT agent!GPT agents, or Generative Pre-trained Transformers, are AI models that can understand human language and generate text based on that understanding. But how can this technology be used in everyday life? Here are just a few examples:  Personal AssistantBy integrating a GPT agent into your daily routine, you can automate repetitive tasks and receive personalized recommendations. Whether it‚Äôs scheduling appointments, ordering groceries, or getting restaurant recommendations, your GPT agent can handle it all.  CustomizationWhile pre-trained models can be useful, they may not always be tailored to your specific needs. Fine-tuning a pre-trained model with your own data can help improve its performance and make it more relevant to your use case. This means that your GPT agent can be customized to handle the tasks you need it to, making it even more useful.  Mental HealthGPT agents can also help improve mental health. By providing a safe and anonymous space to talk about emotions and thoughts, GPT agents can help individuals process their feelings and work through problems. Additionally, GPT agents can provide coping mechanisms and helpful resources for those struggling with mental health issues.  AccessibilityFor those with disabilities or limitations, GPT agents can provide a way to accomplish tasks that may have been difficult otherwise. By using voice commands or text-based interactions, individuals can navigate tasks and access information in a way that works best for them.A GPT agent can improve your everyday life by acting as a personal assistant, being customized to your specific needs, providing a safe space for mental health support, and enhancing accessibility. So why not integrate a GPT agent into your life today?How to Implement a GPT AgentImplementing a GPT agent may seem daunting, but it doesn‚Äôt have to be. Here are a few steps to get started:  Choose a pre-trained model: There are many pre-trained GPT models available. Choose one that fits your needs.  Fine-tune the model: Fine-tune the model on your specific task or application. This will allow it to generate more relevant and accurate outputs.  Integrate the model: Once the model is fine-tuned, integrate it into your workflow or application. This may require some programming knowledge, but there are resources available to help.ConclusionA GPT agent can be a valuable tool for improving productivity and efficiency in your everyday life. By taking advantage of pre-trained models and fine-tuning them for your specific needs, you can save time and resources while generating more accurate and relevant outputs. Give it a try and see how it can benefit you!"
  },
  
  {
    "title": "Building an App with Chat GPT",
    "url": "/posts/building-an-app-with-chat-gpt/",
    "categories": "ai",
    "tags": "ubuntu, docs, chatgpt, app, flask, react, ai, linux",
    "date": "2023-04-20 10:00:00 -0700",
    





    
    "snippet": "Building a GPT Chatbot with Flask and React  ü§ñIn this article, we‚Äôll explore how we built a chatbot using OpenAI‚Äôs GPT model, Flask, and React. We‚Äôll look at the advantages of using GPT for chat ap...",
    "content": "Building a GPT Chatbot with Flask and React  ü§ñIn this article, we‚Äôll explore how we built a chatbot using OpenAI‚Äôs GPT model, Flask, and React. We‚Äôll look at the advantages of using GPT for chat applications and discuss how the chatbot can be implemented.Introduction to TKS-GPT Chat Bot and its AdvantagesGPT, or Generative Pre-trained Transformer, is a powerful language model developed by OpenAI. It has been trained on a diverse range of internet text and has the ability to generate contextually relevant and human-like text responses based on input text.Some advantages of using GPT for chat applications include:  Natural language understanding: GPT is able to understand and generate human-like responses based on input text.  Context-awareness: GPT can maintain context across multiple turns in a conversation, allowing it to generate more relevant and coherent responses.  Flexible use cases: GPT can be used for a variety of applications, such as answering questions, generating text, summarizing content, and more.Building the ChatbotWe built a chatbot using GPT, Flask, and React. Here‚Äôs an overview of the components and the steps taken to create the chatbot:Backend: Flask  Setting up the Flask server: We created a simple Flask server to handle API requests from the frontend. We defined an API endpoint /chat to receive messages from the frontend and send back GPT-generated responses.  Integrating with OpenAI‚Äôs API: We used OpenAI‚Äôs API to interact with the GPT model. When a request is received at the /chat endpoint, we sent the message to the GPT model and received a response, which was then sent back to the frontend.Frontend: React  Setting up the React app: We used Create React App to set up a new React project and installed necessary dependencies, such as Axios for making API requests to the Flask server.  Creating the chat interface: We built a simple chat interface with a text input for the user to enter their message and a chat area to display the conversation history.  Handling user input: We implemented logic to handle user input, such as sending messages by pressing ‚ÄúEnter‚Äù and preventing rapid-fire requests by disabling the ‚ÄúSend‚Äù button while a request is being processed.  Communicating with the Flask server: We used Axios to make API requests to the Flask server, sending the user‚Äôs message and receiving the GPT-generated response.Deployment and Security Considerations  Environment variables: We used environment variables to separate development and production configurations, such as API URLs and API keys.  HTTPS support: We made sure that the application could work with both HTTP and HTTPS by dynamically generating the API URL based on the current protocol.  Dockerizing the application: We created a Dockerfile to containerize the application, making it easier to deploy and manage.ConclusionBy combining GPT with Flask and React, we created a chatbot that can understand and generate contextually relevant responses based on user input. This chatbot can be deployed and used in various applications, providing a powerful and flexible tool for natural language understanding and generation.You can run have this app up and running in minutes using docker. Check out the repo to pull the latest image   TKS-GPT Github Repo all you need is an Open Ai api key."
  },
  
  {
    "title": "Resizing LVM disk on Ubuntu VM",
    "url": "/posts/lvm-resizing-on-ubuntu-vm/",
    "categories": "ubuntu",
    "tags": "ubuntu, docs, resize, parted, proxmox, resize2fs, lvm, linux",
    "date": "2023-03-06 09:00:00 -0800",
    





    
    "snippet": "Resizing LVM storage in a 22.04 Ubuntu VM in Proxmox v7.3So after searching the webs I was trying to resize a proxmox ubuntu vm using LVM storage but wasn‚Äôt able to find the exact solution without ...",
    "content": "Resizing LVM storage in a 22.04 Ubuntu VM in Proxmox v7.3So after searching the webs I was trying to resize a proxmox ubuntu vm using LVM storage but wasn‚Äôt able to find the exact solution without piecing together a few different sites and fumbling through the steps. I was getting an error disk was in use following this guide how-to-enlarge-an-ext4-disk-on-an-ubuntu-proxmox-vmThe IssueYou can select the VM in proxmox and go to hardware and then select your hard disk then select edit, resize ( can only add additional GB of space and not remove ) once you have your extra GB added you should be gtg right? NOPE. If your like me you don‚Äôt like to give to much GB space to a VM if you don‚Äôt know exactly what it will be used for in the long run, using a zfs pool of nvme ssd‚Äôs is precious resources. You can always add later but not take away very easily. First always make a backup before messing around with any system changes.Ok so ssh into the Ubuntu VM. In my case was using Ubuntu 22.04 server and was setup on LVM storage using my zfs pool on proxmox.once in the command line change to root user using sudo suthen the below commands.fdisk -lnoramlly /dev/sda   will show hard drive space, your drive could be different like /dev/sdb1, ect..Take note it will show all partitions like/dev/sda1/dev/sda2/dev/sda3then doparted /dev/sdausing /dev/sda will end up showing (parted) waiting for the next command. type the word  print and then F(parted) printWarning: Not all of the space available to /dev/sda appears to be used, you can fix the GPT to use all of the space (an extra 1048576000blocks) or continue with the current setting?Fix/Ignore? F         it will then show you the different numbers you can select. The partition to resize like 1, 2, 3, or however many partions you have on the disk. You will be able to tell as it is normally the larger size. We are only interested in the main partition we added the extra space to.We will type resizepart ( then select the correct number to resize from above 1,2,3, ect ) mine in this example was 3.Then type   100%(parted) resizepart 3 100%To exit out of parted type  quitthen use the below commandslvextend -l +100%FREE /dev/mapper/ubuntu--vg-ubuntu--lvand thenresize2fs /dev/mapper/ubuntu--vg-ubuntu--lvBingo now your Ubuntu 22.04 VM using LVM storage on proxmox will be correct size. Use the command to see if it worked.df -hHere is another guide on Proxmox forums that had some of the pieces to solve this but the above walk through is what I was able to do to get it to work. resize-disk-of-ubuntu-19-10-vm-on-proxmox.70352Option2 if the first one didn‚Äôt workThis worked on Proxmox VM running Ubuntu 24.04  First verify current disk status:    lsblk        df -h        Check Physical Volume status:    sudo pvs        sudo pvdisplay        Update partition table and resize Physical Volume:    sudo partprobe /dev/sda        sudo pvresize /dev/sda4        Verify Physical Volume was resized correctly:    sudo pvs        sudo pvdisplay        (Should show the full disk space and available free space)    Extend Logical Volume to use all free space:    sudo lvextend -l +100%FREE /dev/ubuntu-vg/ubuntu-lv        Resize the filesystem to use the new space:    sudo resize2fs /dev/mapper/ubuntu--vg-ubuntu--lv        Verify new size:    df -h      Note: Replace sda4 with your actual partition number if different. You can identify the correct partition by checking lsblk output - it will be the large partition that‚Äôs part of the LVM.These steps worked for Ubuntu 24.04 with an LVM setup, which is the default for Proxmox Ubuntu VMs."
  },
  
  {
    "title": "Docker build a simple image",
    "url": "/posts/building-a-basic-docker-image/",
    "categories": "docker",
    "tags": "docker, docs, linux, windows",
    "date": "2023-01-23 09:00:00 -0800",
    





    
    "snippet": "How to build a simple docker image in secondsThe first thing you need is docker installedCreating the DockerfileTo build a simple ‚ÄúHello I did it!‚Äù Docker image, you will need to create a Dockerfil...",
    "content": "How to build a simple docker image in secondsThe first thing you need is docker installedCreating the DockerfileTo build a simple ‚ÄúHello I did it!‚Äù Docker image, you will need to create a Dockerfile that defines the instructions for building the image.The Docker file needs to be just that a file named Dockerfile , all one word and capitol D, in linux it would be :sudo touch Dockerfilethen edit the filesudo nano DockerfilePaste the contents in the file and save it. CTL+X then EnterFROM alpineCMD [\"echo\", \"Hello I did it!\"]This Dockerfile uses the alpine image as a base, and runs the command echo ‚ÄúHello I did it!‚Äù when the container is started.Building the ImageOnce you have created the Dockerfile, you can build the image using the docker build command. Here is an example command that you can use to build the image:docker build -t my-hello-image .This command tells Docker to build an image using the Dockerfile in the current directory (indicated by the . at the end) and tag the image with the name my-hello-image.Running the ImageOnce the image is built, you can run it using the docker run command. Here is an example command that you can use to run the image:docker run my-hello-imageThis command tells Docker to run the my-hello-image image and output the message ‚ÄúHello I did it!‚ÄùAnd that‚Äôs it, you can now use the command docker run my-hello-image to run your newly created image and see the message: \"Hello I did it!\" printed on the screen.If you want to see your image just use sudo docker images and you will be shown that your image was made REPOSITORY             TAG       IMAGE ID       CREATED          SIZEmy-hello-image         latest    26cdf940f9e6   50 minutes ago   7.04MBTo remove your imageJust use the command rmi and ‚Äìforce , you can also remove the alpine image that was made when building the image the same way.sudo docker rmi &lt;IMAGE-ID&gt; --force"
  },
  
  {
    "title": "What is Bitcoin?",
    "url": "/posts/What-is-Bitcoin/",
    "categories": "bitcoin",
    "tags": "docs, bitcoin, crypto, blockchain",
    "date": "2023-01-10 09:00:00 -0800",
    





    
    "snippet": "What is Bitcoin?Bitcoin is a type of digital currency that you can use to buy things online, or you can trade it for regular money. It‚Äôs different from regular money because it‚Äôs not controlled by ...",
    "content": "What is Bitcoin?Bitcoin is a type of digital currency that you can use to buy things online, or you can trade it for regular money. It‚Äôs different from regular money because it‚Äôs not controlled by a government or a bank. Instead, it‚Äôs run by a network of computers all over the world that work together to make sure everything is fair and accurate.When someone wants to send some bitcoin to someone else, they broadcast a message to the network with the details of the transaction, like how much bitcoin is being sent and who it‚Äôs being sent to. The computers in the network then work together to make sure that the person sending the bitcoin actually has it and that it‚Äôs not being spent twice.Once the computers in the network approve the transaction, it gets added to a big public list of all the transactions that have ever happened with bitcoin, called the blockchain. And that‚Äôs how the bitcoin gets moved from one person to another.And the special thing about bitcoin is that it is created through a process called mining, in which powerful computers use complex algorithms to solve complex mathematical puzzles to validate the transactions on the network, and for each block of transactions they validate, they get rewarded with a certain amount of bitcoins. The reward they get comes from the small fees that are paid when a bitcoin transaction is sent.Bitcoin transactionConverting cash to bitcoin and back. After receiving Products and Goods some or all bitcoin can be held in a bitcoin wallet or it can be immediately sent back to cash.A Bitcoin WalletA bitcoin wallet is a digital wallet that you can use to store, receive and send bitcoins.To receive bitcoin, you first need to create a bitcoin wallet. There are many different types of wallets available, including software wallets that you can download to your computer or mobile device, and online wallets that you can access through a website.Once you have a wallet, you will be given a unique ‚Äúbitcoin address‚Äù that you can share with others. This is like a bank account number, but for bitcoin.To receive bitcoin, you simply give your bitcoin address to the person who wants to send you bitcoin. They will then use their own wallet to send the bitcoin to your address.To send bitcoin, you will need to open your wallet and enter the bitcoin address of the person you want to send the bitcoin to, as well as the amount of bitcoin you want to send. Then you can confirm the transaction and the bitcoin will be transferred to the recipient‚Äôs address.Keep in mind that the transactions on the bitcoin network are irreversible, so it is important to double check the address and the amount before confirming the transaction. And also the transaction may take some minutes to be confirmed by the network.If looking for a bitcoin wallet we have a great selection over on the TKS help site. Everything from desktop to mobile, easy to complex multi-sig wallets. Check it out HEREBoth merchants and customers can benefit from using bitcoin in different waysLower transaction fees: Bitcoin transactions typically have much lower fees compared to traditional payment methods like credit cards or bank transfers. This can be especially beneficial for merchants, as it allows them to save money on transaction fees and pass some of those savings on to their customers.Faster transactions: Bitcoin transactions are processed on a decentralized network, which means that they can be confirmed and completed much faster than traditional payment methods. This allows merchants to process more transactions in less time, and also lets customers receive their goods or services more quickly.Increased security: Bitcoin transactions are secured by complex cryptography, making them much more secure than traditional payment methods. This can give merchants and customers peace of mind knowing that their financial information is protected.Increased privacy: Bitcoin transactions do not require the sharing of personal information, like credit card numbers or bank account details. This can provide a greater level of privacy for both merchants and customers.Borderless transactions: Bitcoin transactions are not restricted by geographical borders, allowing merchants and customers to conduct transactions with anyone anywhere in the world.Accessibility: Bitcoin can be used by anyone with an internet connection, regardless of whether they have a bank account or credit history. This can allow merchants to reach new customers and increase their customer base.Downloading and setting up a mobile bitcoin wallet is relatively easy and can typically be done in a few simple steps. Here‚Äôs an example of the process:Search for a reputable mobile bitcoin wallet in the app store of your choice and download it to your mobile device. We recommend Muun Mobile WalletOpen the app and create a new wallet by following the prompts. This may include creating a password or PIN code for added security.Once your wallet is set up, you will be given a unique ‚Äúseed phrase‚Äù or ‚Äúmnemonic phrase‚Äù. This is a series of words that you will need to write down and store in a safe place. This seed phrase is used to recover your wallet in case you lose your device or forget your password.Write down the seed phrase on a piece of paper and store it in a secure location. You might want to consider storing multiple copies in different locations or writing it down by hand.Keep in mind that the seed phrase is the only way to recover your wallet and access your funds if you lose your device or forget your password, so it is important to keep it safe and secure.Once you have saved your seed phrase, you will be able to use your mobile wallet to send and receive bitcoins, check your balance and transaction history, and more.Overall, downloading and setting up a mobile bitcoin wallet is a relatively easy process that can typically be completed in just a few minutes. The most important part is to save the seed phrase securely, so you can recover the wallet if needed.Once you have bitcoin in your wallet which could be either on a centralized exchange like Coinbase or a mobile wallet like Muun Wallet or even in a hardware wallet like Ledger you can then be able to purchase goods online with ease."
  },
  
  {
    "title": "How a VPN works",
    "url": "/posts/How-a-VPN-works/",
    "categories": "privacy",
    "tags": "privacy, docs",
    "date": "2023-01-10 09:00:00 -0800",
    





    
    "snippet": "What is a VPN?A Virtual Private Network (VPN) is a technology that allows you to create a secure connection to another network over the internet. It works by creating an encrypted ‚Äútunnel‚Äù between ...",
    "content": "What is a VPN?A Virtual Private Network (VPN) is a technology that allows you to create a secure connection to another network over the internet. It works by creating an encrypted ‚Äútunnel‚Äù between your device and the VPN server, which protects your data and online activities from being intercepted by hackers or other malicious actors.How does a VPN work?      Your device connects to the VPN server. This connection is established using a protocol such as OpenVPN or IKEv2.        The VPN server assigns you a new IP address, which can be used to mask your true location.        Once connected, all of your internet traffic is routed through the VPN server and is encrypted. This means that anyone intercepting your traffic will only see encrypted data and will not be able to see what you‚Äôre doing online.        The VPN server then forwards your traffic to its destination, such as a website or online service.        Once you‚Äôre done using the VPN, you can disconnect from the server and your internet traffic will return to its normal unencrypted state.  It is important to note that a VPN can protect your privacy and security while you are connected to the internet, but it is not a substitute for safe browsing habits and should be used in conjunction with other security measures.You can use a VPN to protect your privacy, to access blocked content, or to ensure a secure connection when using public Wi-Fi. It is important to be aware that a VPN can also slow down your internet connection, and also there are free VPNs that may not be safe to use. It is recommended to research and choose a reputable VPN service that has a clear privacy policy and uses strong encryption standards."
  },
  
  {
    "title": "Exploring GPT: How the ChatGPT Model Works",
    "url": "/posts/chatgpt/",
    "categories": "ai",
    "tags": "ai, chatgpt",
    "date": "2023-01-10 09:00:00 -0800",
    





    
    "snippet": "Introduction to ChatGPTChatGPT is a computer program that can talk like a human. It can understand what you say and respond to you just like a friend would. Imagine you have a robot friend that you...",
    "content": "Introduction to ChatGPTChatGPT is a computer program that can talk like a human. It can understand what you say and respond to you just like a friend would. Imagine you have a robot friend that you can talk to and ask it questions and it can answer you back! It‚Äôs like having a magical talking computer!The more complex explaination is ChatGPT is an open-source conversational language model based on the GPT (Generative Pre-training Transformer) architecture, it‚Äôs been trained to predict the next token in a conversational context.  Diagram of the ChatGPT modelTo learn more about the GPT architecture, you can refer to this paperIn this post, we‚Äôll explore how ChatGPT can be used in a chatbot application.Generating Responses with ChatGPTHere is an example of how you might use the model to generate a response to a user‚Äôs message in a chatbot application:import openai_secret_manager# Get API keysecrets = openai_secret_manager.get_secret(\"openai\")api_key = secrets[\"api_key\"]# Use the API key to create a session with the APIimport openaiopenai.api_key = api_key# Use the session to generate a response to the user's messageprompt = (f\"Your message\")completions = openai.Completion.create(    engine=\"text-davinci-002\",    prompt=prompt,    max_tokens=1024,    n=1,    stop=None,    temperature=0.7,)# Print the generated responsemessage = completions.choices[0].textprint(message)If you head over to ChatGPT and sign up you can start testing some of it‚Äôs features. It‚Äôs free. Just start asking it?, I guess it‚Äôs an it, some questions."
  },
  
  {
    "title": "Welcome",
    "url": "/posts/welcome/",
    "categories": "news",
    "tags": "news, projects, docs",
    "date": "2023-01-10 09:00:00 -0800",
    





    
    "snippet": "Welcome to our Github Docs SiteHello and welcome to our site on github pages!What will become of this little space on the interwebs? We already have a help center TKS Help CenterWell I‚Äôm sure there...",
    "content": "Welcome to our Github Docs SiteHello and welcome to our site on github pages!What will become of this little space on the interwebs? We already have a help center TKS Help CenterWell I‚Äôm sure there will be some bitcoin related content as well as some DevOps related projects. Post to better protect your privacy online and with payments.Some ‚ÄúHow to‚Äù blogs and we will see what else we can come up with.To open a lightning channel with us for payments on the store click here"
  }
  
]

